{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dd6c7af988>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Absents = pd.read_csv(\"train_data.csv\")\n",
    "X_test  = pd.read_csv(\"test_data.csv\")\n",
    "Y_test  = pd.read_csv(\"sample_submission.csv\")\n",
    "sns.distplot(Absents['Absent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre tratemento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239554</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>261756</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>170</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>261756</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>170</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>261756</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>172</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>261756</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>196</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>291</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>261756</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>171</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reason for absence  Month of absence  Day of the week  Seasons  \\\n",
       "0                    26                 7                3        1   \n",
       "1                     0                 7                3        1   \n",
       "2                    23                 7                4        1   \n",
       "3                     7                 7                5        1   \n",
       "4                    23                 7                5        1   \n",
       "..                  ...               ...              ...      ...   \n",
       "495                  28                 9                3        1   \n",
       "496                  28                 9                3        1   \n",
       "497                  28                 9                3        1   \n",
       "498                  23                 9                3        1   \n",
       "499                  28                 9                5        1   \n",
       "\n",
       "     Transportation expense  Distance from Residence to Work  Service time  \\\n",
       "0                       289                               36            13   \n",
       "1                       118                               13            18   \n",
       "2                       179                               51            18   \n",
       "3                       279                                5            14   \n",
       "4                       289                               36            13   \n",
       "..                      ...                              ...           ...   \n",
       "495                     246                               25            16   \n",
       "496                     246                               25            16   \n",
       "497                     118                               10            10   \n",
       "498                     155                               12            14   \n",
       "499                     291                               31            12   \n",
       "\n",
       "     Age  Work load Average/day   Hit target  Disciplinary failure  Education  \\\n",
       "0     33                  239554          97                     0          1   \n",
       "1     50                  239554          97                     1          1   \n",
       "2     38                  239554          97                     0          1   \n",
       "3     39                  239554          97                     0          1   \n",
       "4     33                  239554          97                     0          1   \n",
       "..   ...                     ...         ...                   ...        ...   \n",
       "495   41                  261756          87                     0          1   \n",
       "496   41                  261756          87                     0          1   \n",
       "497   37                  261756          87                     0          1   \n",
       "498   34                  261756          87                     0          1   \n",
       "499   40                  261756          87                     0          1   \n",
       "\n",
       "     Son  Social drinker  Social smoker  Pet  Weight  Height  Body mass index  \n",
       "0      2               1              0    1      90     172               30  \n",
       "1      1               1              0    0      98     178               31  \n",
       "2      0               1              0    0      89     170               31  \n",
       "3      2               1              1    0      68     168               24  \n",
       "4      2               1              0    1      90     172               30  \n",
       "..   ...             ...            ...  ...     ...     ...              ...  \n",
       "495    0               1              0    0      67     170               23  \n",
       "496    0               1              0    0      67     170               23  \n",
       "497    0               0              0    0      83     172               28  \n",
       "498    2               1              0    0      95     196               25  \n",
       "499    1               1              0    1      73     171               25  \n",
       "\n",
       "[500 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs = [x for x in Absents['Absent'] if x == 1]\n",
    "workload = [int(x.replace(\",\",\"\")) for x in Absents['Work load Average/day ']]\n",
    "Absents['Work load Average/day '] = workload\n",
    "\n",
    "Absents = Absents.drop(columns = 'ID')\n",
    "X_test  = X_test.drop(columns  = 'ID')\n",
    "\n",
    "AbsentsY = Absents['Absent'] \n",
    "AbsentsX = Absents.drop(columns = 'Absent')\n",
    "AbsentsX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.194471</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.194471</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.194471</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.194471</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.194471</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474074</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474074</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137037</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640741</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reason for absence  Month of absence  Day of the week  Seasons  \\\n",
       "0              0.928571          0.545455             0.25      0.0   \n",
       "1              0.000000          0.545455             0.25      0.0   \n",
       "2              0.821429          0.545455             0.50      0.0   \n",
       "3              0.250000          0.545455             0.75      0.0   \n",
       "4              0.821429          0.545455             0.75      0.0   \n",
       "..                  ...               ...              ...      ...   \n",
       "495            1.000000          0.727273             0.25      0.0   \n",
       "496            1.000000          0.727273             0.25      0.0   \n",
       "497            1.000000          0.727273             0.25      0.0   \n",
       "498            0.821429          0.727273             0.25      0.0   \n",
       "499            1.000000          0.727273             0.75      0.0   \n",
       "\n",
       "     Transportation expense  Distance from Residence to Work  Service time  \\\n",
       "0                  0.633333                         0.659574      0.384615   \n",
       "1                  0.000000                         0.170213      0.576923   \n",
       "2                  0.225926                         0.978723      0.576923   \n",
       "3                  0.596296                         0.000000      0.423077   \n",
       "4                  0.633333                         0.659574      0.384615   \n",
       "..                      ...                              ...           ...   \n",
       "495                0.474074                         0.425532      0.500000   \n",
       "496                0.474074                         0.425532      0.500000   \n",
       "497                0.000000                         0.106383      0.269231   \n",
       "498                0.137037                         0.148936      0.423077   \n",
       "499                0.640741                         0.553191      0.346154   \n",
       "\n",
       "          Age  Work load Average/day   Hit target  Disciplinary failure  \\\n",
       "0    0.193548                0.194471    0.842105                   0.0   \n",
       "1    0.741935                0.194471    0.842105                   1.0   \n",
       "2    0.354839                0.194471    0.842105                   0.0   \n",
       "3    0.387097                0.194471    0.842105                   0.0   \n",
       "4    0.193548                0.194471    0.842105                   0.0   \n",
       "..        ...                     ...         ...                   ...   \n",
       "495  0.451613                0.322830    0.315789                   0.0   \n",
       "496  0.451613                0.322830    0.315789                   0.0   \n",
       "497  0.322581                0.322830    0.315789                   0.0   \n",
       "498  0.225806                0.322830    0.315789                   0.0   \n",
       "499  0.419355                0.322830    0.315789                   0.0   \n",
       "\n",
       "     Education   Son  Social drinker  Social smoker  Pet    Weight    Height  \\\n",
       "0          0.0  0.50             1.0            0.0  0.2  0.653846  0.272727   \n",
       "1          0.0  0.25             1.0            0.0  0.0  0.807692  0.454545   \n",
       "2          0.0  0.00             1.0            0.0  0.0  0.634615  0.212121   \n",
       "3          0.0  0.50             1.0            1.0  0.0  0.230769  0.151515   \n",
       "4          0.0  0.50             1.0            0.0  0.2  0.653846  0.272727   \n",
       "..         ...   ...             ...            ...  ...       ...       ...   \n",
       "495        0.0  0.00             1.0            0.0  0.0  0.211538  0.212121   \n",
       "496        0.0  0.00             1.0            0.0  0.0  0.211538  0.212121   \n",
       "497        0.0  0.00             0.0            0.0  0.0  0.519231  0.272727   \n",
       "498        0.0  0.50             1.0            0.0  0.0  0.750000  1.000000   \n",
       "499        0.0  0.25             1.0            0.0  0.2  0.326923  0.242424   \n",
       "\n",
       "     Body mass index  \n",
       "0           0.578947  \n",
       "1           0.631579  \n",
       "2           0.631579  \n",
       "3           0.263158  \n",
       "4           0.578947  \n",
       "..               ...  \n",
       "495         0.210526  \n",
       "496         0.210526  \n",
       "497         0.473684  \n",
       "498         0.315789  \n",
       "499         0.315789  \n",
       "\n",
       "[500 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def normalize_dataset():\n",
    "    global AbsentsX,X_testas\n",
    "    x  = AbsentsX.values \n",
    "    x2 = X_test.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    scaler    = min_max_scaler.fit(x)\n",
    "    x_scaled  = scaler.transform(x)\n",
    "    x2_scaled = scaler.transform(x2)\n",
    "    df  = pd.DataFrame(x_scaled)\n",
    "    df2 = pd.DataFrame(x2_scaled)\n",
    "\n",
    "    i = 0\n",
    "    for x in AbsentsX:\n",
    "        AbsentsX[x] = df[i]\n",
    "        X_test [x] = df2[i]\n",
    "        i+=1\n",
    "\n",
    "\n",
    "        \n",
    "def standardize_dataset():\n",
    "    global AbsentsX,X_test\n",
    "    x  =  AbsentsX.values\n",
    "    x2 = X_test.values\n",
    "    standart_scaler = preprocessing.StandardScaler()\n",
    "    scaler = standart_scaler.fit(x)\n",
    "    x_scaled  = scaler.transform(x)\n",
    "    x2_scaled = scaler.transform(x2) \n",
    "    df  = pd.DataFrame(x_scaled)\n",
    "    df2 = pd.DataFrame(x2_scaled)\n",
    "\n",
    "    i = 0\n",
    "    for x in AbsentsX:\n",
    "        AbsentsX[x] = df[i]\n",
    "        X_test[x]  = df2[i]\n",
    "        i+=1\n",
    "        \n",
    "def binarize_dataset():\n",
    "    global AbsentsX,X_test\n",
    "    x  =  AbsentsX.values\n",
    "    x2 = X_test.values\n",
    "    Binarizer = preprocessing.Binarizer()\n",
    "    binarizer = Binarizer.fit(x)\n",
    "    x_scaled  = binarizer.transform(x)\n",
    "    x2_scaled = binarizer.transform(x2) \n",
    "    df  = pd.DataFrame(x_scaled)\n",
    "    df2 = pd.DataFrame(x2_scaled)\n",
    "\n",
    "    i = 0\n",
    "    for x in AbsentsX:\n",
    "        AbsentsX[x] = df[i]\n",
    "        X_test[x]  = df2[i]\n",
    "        i+=1\n",
    "\n",
    "\n",
    "##binarize_dataset()\n",
    "normalize_dataset()\n",
    "##standardize_dataset()\n",
    "AbsentsX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396296</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.339296</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.339296</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.377540</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.418519</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.377540</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.377540</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reason for absence  Month of absence  Day of the week   Seasons  \\\n",
       "0              0.821429          0.727273             1.00  0.000000   \n",
       "1              0.821429          0.727273             1.00  0.000000   \n",
       "2              0.821429          0.727273             0.00  0.000000   \n",
       "3              0.821429          0.727273             0.50  0.000000   \n",
       "4              0.821429          0.727273             0.00  0.000000   \n",
       "..                  ...               ...              ...       ...   \n",
       "235            0.500000          0.545455             0.25  0.000000   \n",
       "236            0.392857          0.545455             0.25  0.000000   \n",
       "237            0.000000         -0.090909             0.25  0.000000   \n",
       "238            0.000000         -0.090909             0.50  0.333333   \n",
       "239            0.000000         -0.090909             1.00  0.666667   \n",
       "\n",
       "     Transportation expense  Distance from Residence to Work  Service time  \\\n",
       "0                  0.225926                         0.446809      0.230769   \n",
       "1                  0.481481                         0.425532      0.423077   \n",
       "2                  0.225926                         0.978723      0.576923   \n",
       "3                  0.396296                         0.446809      0.230769   \n",
       "4                  0.225926                         0.446809      0.230769   \n",
       "..                      ...                              ...           ...   \n",
       "235                0.633333                         0.659574      0.384615   \n",
       "236                0.433333                         0.127660      0.423077   \n",
       "237                0.000000                         0.191489      0.384615   \n",
       "238                0.418519                         0.638298      0.423077   \n",
       "239                0.225926                         0.851064      0.423077   \n",
       "\n",
       "          Age  Work load Average/day   Hit target  Disciplinary failure  \\\n",
       "0    0.096774                0.322830    0.315789                   0.0   \n",
       "1    0.645161                0.322830    0.315789                   0.0   \n",
       "2    0.354839                0.322830    0.315789                   0.0   \n",
       "3    0.032258                0.322830    0.315789                   0.0   \n",
       "4    0.096774                0.322830    0.315789                   0.0   \n",
       "..        ...                     ...         ...                   ...   \n",
       "235  0.193548                0.339296    0.631579                   0.0   \n",
       "236  0.322581                0.339296    0.631579                   0.0   \n",
       "237  0.419355                0.377540    0.736842                   0.0   \n",
       "238  0.387097                0.377540    0.736842                   0.0   \n",
       "239  0.838710                0.377540    0.736842                   0.0   \n",
       "\n",
       "     Education   Son  Social drinker  Social smoker  Pet    Weight    Height  \\\n",
       "0          1.0  0.00             0.0            0.0  0.0  0.000000  0.242424   \n",
       "1          0.0  0.50             0.0            0.0  0.2  0.576923  0.060606   \n",
       "2          0.0  0.00             1.0            0.0  0.0  0.634615  0.212121   \n",
       "3          0.0  0.25             0.0            0.0  0.4  0.250000  0.181818   \n",
       "4          1.0  0.00             0.0            0.0  0.0  0.000000  0.242424   \n",
       "..         ...   ...             ...            ...  ...       ...       ...   \n",
       "235        0.0  0.50             1.0            0.0  0.2  0.653846  0.272727   \n",
       "236        1.0  0.25             0.0            0.0  0.2  0.615385  0.272727   \n",
       "237        0.0  0.25             1.0            0.0  1.6  0.807692  0.212121   \n",
       "238        0.0  0.50             1.0            0.0  0.4  0.846154  0.212121   \n",
       "239        0.0  0.25             0.0            0.0  0.2  0.403846  0.363636   \n",
       "\n",
       "     Body mass index  \n",
       "0           0.000000  \n",
       "1           0.684211  \n",
       "2           0.631579  \n",
       "3           0.263158  \n",
       "4           0.000000  \n",
       "..               ...  \n",
       "235         0.578947  \n",
       "236         0.526316  \n",
       "237         0.789474  \n",
       "238         0.842105  \n",
       "239         0.315789  \n",
       "\n",
       "[240 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reinserir a coluna absent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsentsX.insert(len(AbsentsX.columns),'Absent',AbsentsY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancear o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "210\n"
     ]
    }
   ],
   "source": [
    "def balance_dataset(nr_0,nr_1):\n",
    "    global AbsentsX\n",
    "    abs_shuffled = AbsentsX.sample(frac=1,random_state=4)\n",
    "    A0 = abs_shuffled.loc[abs_shuffled['Absent'] == 1].sample(n=nr_0,random_state=4)\n",
    "    A1 = abs_shuffled.loc[abs_shuffled['Absent'] == 0].sample(n=nr_1,random_state=4)\n",
    "    \n",
    "    balanced_absents = pd.concat([A0,A1])\n",
    "    AbsentsX = balanced_absents.sample(frac=1,random_state=4)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "A0 = len(AbsentsX[AbsentsX['Absent'] == 0])\n",
    "A1 = len(AbsentsX[AbsentsX['Absent'] == 1])\n",
    "\n",
    "nr_elements_dataset = A0\n",
    "\n",
    "if A1 < A0:\n",
    "    nr_elements_dataset = A1\n",
    "\n",
    "print(nr_elements_dataset)\n",
    "balance_dataset(nr_elements_dataset,nr_elements_dataset)\n",
    "##balance_dataset(125,nr_elements_dataset)\n",
    "\n",
    "print(len(AbsentsX))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removemos os outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = AbsentsX.quantile(0.975)\n",
    "q4 = AbsentsX.quantile(0.025)\n",
    "\n",
    "\n",
    "OUTLIER_COLUMNS = ['Reason for absence',\"Age\",\"Transportation expense\",\n",
    "                  \"Service time\",\"Work load Average/day \",\"Hit target\",\n",
    "                  \"Weight\",\"Height\",\"Body mass index\"]\n",
    "\n",
    "def remove_outliers(OUTLIER_COLUMNS):\n",
    "    global AbsentsX\n",
    "    for i in OUTLIER_COLUMNS:\n",
    "        AbsentsX = AbsentsX.drop(AbsentsX[AbsentsX[i] > q1[i]].index)\n",
    "        AbsentsX = AbsentsX.drop(AbsentsX[AbsentsX[i] < q4[i]].index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "remove_outliers(OUTLIER_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "print(len(Absents[Absents['Absent'] == 1]))\n",
    "print(len(Absents[Absents['Absent'] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection + extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Absent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.222412</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.396296</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.794001</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.274896</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.451612</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>481</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.253690</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.593616</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.265374</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.396296</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.696867</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.345141</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.418519</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.510502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reason for absence  Month of absence  Day of the week   Seasons  \\\n",
       "403            0.500000          0.181818             0.25  0.666667   \n",
       "183            1.000000          0.181818             0.00  0.666667   \n",
       "65             0.821429          0.818182             0.75  1.000000   \n",
       "327            0.392857          0.909091             0.50  1.000000   \n",
       "481            0.892857          0.636364             0.00  0.000000   \n",
       "..                  ...               ...              ...       ...   \n",
       "123            0.964286          0.000000             0.25  0.333333   \n",
       "384            0.392857          0.090909             0.50  0.333333   \n",
       "185            0.821429          0.272727             0.50  0.666667   \n",
       "254            0.821429          0.636364             0.00  0.000000   \n",
       "276            0.000000          0.727273             0.25  0.000000   \n",
       "\n",
       "     Transportation expense  Distance from Residence to Work       Age  \\\n",
       "403                0.000000                         0.170213  0.741935   \n",
       "183                0.396296                         0.446809  0.032258   \n",
       "65                 0.225926                         0.446809  0.096774   \n",
       "327                0.000000                         0.106383  0.322581   \n",
       "481                0.225926                         0.361702  0.419355   \n",
       "..                      ...                              ...       ...   \n",
       "123                0.000000                         0.106383  0.322581   \n",
       "384                0.144444                         0.468085  0.064516   \n",
       "185                0.396296                         0.446809  0.032258   \n",
       "254                0.633333                         0.659574  0.193548   \n",
       "276                0.418519                         0.638298  0.387097   \n",
       "\n",
       "     Work load Average/day   Hit target  Disciplinary failure   Son  \\\n",
       "403                0.222412    0.894737                   0.0  0.25   \n",
       "183                0.794001    0.736842                   0.0  0.25   \n",
       "65                 0.274896    0.631579                   0.0  0.00   \n",
       "327                0.451612    0.842105                   0.0  0.00   \n",
       "481                0.253690    0.631579                   0.0  0.50   \n",
       "..                      ...         ...                   ...   ...   \n",
       "123                0.593616    0.736842                   0.0  0.00   \n",
       "384                0.265374    0.789474                   0.0  0.00   \n",
       "185                0.696867    0.789474                   0.0  0.25   \n",
       "254                0.345141    0.684211                   0.0  0.50   \n",
       "276                0.510502    0.000000                   1.0  0.50   \n",
       "\n",
       "     Social drinker    Weight    Height  Body mass index  Absent  \n",
       "403             1.0  0.807692  0.454545         0.631579       1  \n",
       "183             0.0  0.250000  0.181818         0.263158       0  \n",
       "65              0.0  0.000000  0.242424         0.000000       0  \n",
       "327             0.0  0.519231  0.272727         0.473684       1  \n",
       "481             0.0  0.134615  0.212121         0.157895       0  \n",
       "..              ...       ...       ...              ...     ...  \n",
       "123             0.0  0.519231  0.272727         0.473684       1  \n",
       "384             1.0  0.365385  0.666667         0.157895       1  \n",
       "185             0.0  0.250000  0.181818         0.263158       0  \n",
       "254             1.0  0.653846  0.272727         0.578947       0  \n",
       "276             1.0  0.846154  0.212121         0.842105       0  \n",
       "\n",
       "[178 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGZCAYAAAAUzjLvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd5xU1f3/8debBQFFwYIGK1GxIqIgigXBYEuMGmOBaCIaJRqNLerPfGOMmmIhsWAnFtTYYscSFQ1F6b3ZWyKKBQuK9N3P749zBq7DzM7szt3dYffz9DGPnbn33M89d1j3nnvuuecjM8M555xzTVezhq6Ac8455xqWNwacc865Js4bA84551wT540B55xzronzxoBzzjnXxHljwDnnnGvivDFQC5IqJU2XNFvSU5LaNXSdkiQNkjRH0qCU4/aW9HSaMZ1zzjU8bwzUzmIz62pmnYEvgDMaukJZfgXsbmYXFFNYUvM6ro9zzrky5o2B0o0DNst8kHSBpEmSZkq6LLH8CUlT4hX7wLisQtLQ2MMwS9K5cXlXSeNjjMclrR+Xj5R0laSJkt6UtF92ZSQNA9YBJkg6TtJWkl6KsV6StGUsN1TSNZJGAFdlxego6WVJU+Nr78Tq9WKdXpV0q6Rm1RzHNpKei8f9sqQdEvseLGmspHclHZ3Y94UxxgxJV1YXxznnXDr8irAEkiqAHwB3xM8HAZ2AHoCAYZJ6mdlo4GQz+0JSa2CSpEeBjsBmsYeBxO2Ge4DfmNkoSZcDfwTOieuam1kPST+My/sm62Rmh0taaGZdY8yngHvM7G5JJwODgSNj8e2AvmZWmXVonwIHmtkSSZ2AB4DucV0PYCfgv8BzwFHAe3mOYwhwmpm9JWlP4GbggLiuA7AvsAMwDHhE0qGxbnua2SJJGxQRJ/NvMRAYCHDz3//c7ZRf9KdUN+9+Sckxdlq6vOQYADNatkglztopTTh6QOsvUokz45v1U4nzdYVSidOlalHJMfaZPyGFmsB1m/RJJU77Fen8o69blf1nonamtKpIJc4BS5emEmefjx8p+Zdn+fx3i/6SW2y0dTq/rCnzxkDttJY0nXAynwIMj8sPiq9p8XMbQuNgNHCWpJ/E5VvE5W8AW0u6AXgGeEFSW6CdmY2KZe8GHk7s+7H4c0rcfyE9CSdsgHuBqxPrHs7REABoAdwoqStQSWg0ZEw0s3cBJD1AOKG/lOM42gB7Aw9LK3/3WybiPGFmVcCrkjaJy/oCd5nZIoDYeCoUh1h2CKHRUKP/MZ1zznljoLYWm1nXeOJ+mjBmYDChN+AKM7stWVhSb8KJrme84h0JtDKzLyXtChwcYxwLnFtg35nmcCW1+/dLnii/zVPmXOATYFfCraQlebYHsDzHcQ7wVaaHIodks16Jn9nxmxWI45xzDSulXpOG5GMGSmBmC4CzgPMltQCeB06OV7NI2kzSxkBb4MvYENgB2Cuu3whoZmaPAn8gDPpbAHyZGA/wc2AUtTcW6BffHw+8UsQ2bYF58cr950CyX6+HpO9LagYcB7yS5zi+Bt6TdEw8VsUGQ3VeIHx/a8dtNqhlHOecqz+VK4p/lSnvGSiRmU2TNAPoZ2b3StoRGBe7tBcCJxDurZ8maSbh1sD4uPlmwF3xxArwu/jzRODWeFJ8FziphCqeBdwp6QLgsyJj3Qw8Gk/AI/huD8I44EpgF8Ltj8fj+1zHcTxwi6SLCbceHgRm5NupmT0Xb01MlrQMeBb4v5rGcc65+hSum9Zs8hTGrrFJa8yADyDMzwcQ5ucDCKvXGAcQLps7q+gvea3Nd/EBhM4551yj0wh6Brwx4JxzzpWiEQwg9MaAa3TS6N4H+PXUy0uO8cQuf0ihJnBqn3mpxJn43EapxPmmarWnO2ulS5svU4lzw/I2qcS5Z/mCkmOM2qBnCjWBJcvSucXUsf1XqcT5cP56qcTZakU6px2pjG5xe8+Ac84517RZGT8lUCx/tNA555wrRVVV8a8CJB0i6Q1Jb0u6KMf65BTzIyVtnsYheGPAOeecK4VVFf+qRpzi/ibgUMK07/0l7ZRV7G+EKea7AJcDV6RxCN4YcM4550pRVVn8q3o9gLfN7F0zW0aYU+WIrDI7EaaAhzAPTPb6WvHGQB2RZJLuTXxuLukzSU/XMl47Sb9OfO5d21hx+x0kTZc0TdI2RW7zfpxt0DnnXEYNegYkDZQ0OfEamIi0GfBB4vNcEllxoxnAT+P7nwDrStqw1EPwxkDd+RboHLMUAhwIfFhCvHbArwuWKt6RwJNmtpuZvZNiXOeca1pqMB2xmQ0xs+6J15BEpFwTEmU/NnE+sL+kacD+hPNKySMYvTFQt/4N/Ci+709IBQyEefclPREHgYyX1CUuv1TSnXFgyLuSzoqbXAlsE6/mB8VlbSQ9Iul1SfcpkdYvsZ+uMf5MSY9LWj+mPz4HOEXSiBzb3BJbrHMkXZa1+gJJE+Nr21j+GEmzJc2QNDouq5A0SNKkuO9fxeW947GtVm9Je0gaG+NMlLRuvjjOOVc20htAOJeQ1TZjc+CjZAEz+8jMjjKz3YDfx2UlPxPrjYG69SDQT1IroAuQnKf0MmBaHATyf8A9iXU7EDIA9gD+qJAE6SLgHTPramYXxHK7EU7qOwFbA/vkqMM9wP+L+5kF/NHMngVuBa41s1xznv7ezLrHOu+faahEX5tZD+BG4Lq47BLgYDPbFTg8LvslsMDM9gD2AE6V9P189Za0FvAQcHaM0xdYXCDOSsmut7EL38pxSM45VzfMKot+FTAJ6KSQDG4tQpK5YckCkjbKygNzZxrH4I2BOmRmM4GOhF6BZ7NW7wvcG8v9B9hQISUywDNmttTM5gOfApvk2cVEM5sbswtOj/taKcZrZ2aZrId3A72KqPqxkqYC04CdCSftjAcSPzOzq4wBhko6lVUZDg8CfiFpOqERtCHQqZp6b0/IlDgpfidfm9mKAnFWSna97d1mtdXOOVd3UnqaIP7NO5OQAfc14F9mNkfS5ZIyF1q9gTckvUk4N/wljUPwSYfq3jDCoyC9CSeyjOruDSUzcFSS/9+p2HJFi1fd5wN7mNmXkoYCrXLUceV7MztN0p6EWyLTY+ZBAb8xs+ez4vfOU2+x+r0x8sVxzrmyUcT8AcWKPbfPZi27JPH+EeCR1HYYec9A3bsTuNzMZmUtH01IzZs5Qc43s6+rifMNsG5NdhzvI30pab+46OfAqGo2AViPMPhxgaRNCM+7Jh2X+DkOQNI2ZjYh/sLOJ9zzeh44Pd7iQNJ2ktapZr+vA5tK2iOWX1dS81rEcc65+pVSz0BD8p6BOmZmc4Hrc6y6FLhL0kxgEXBigTifSxojaTZhYOIzRVbhROBWSWsD7wInFdjPjDhKdU4sPyarSEtJEwgNyf5x2SBJnQhX8S8RHn3J3CKZGgcIfkZ4giHffpdJOg64IT6BsZgwbuD2msRxzrl6V5lOHomG5I2BOmJmq2VOMbORwMj4/gtyTBZhZpdmfe6ceP+zrOIjE+vOzFOP6cBehfaTtW5AnuUd49vLspYflas4YWDk/2UtH0meesfxAqvVNU8c55wrDyneJmgo3hhwzjnnSlHG3f/F8saAa3R2WppOl10a6YePnPWnFGoC/+qSTlrmdZTOH62NKtKJ89HXNRoGk1e3Fi1SiXPYivYlx3ivIp0/qxunlAnvsy/SGWKzyCoKFypCC0sn9fDiqjI6fXnPgHPOOdfEeWPAOeeca9rMBxA655xzTZyPGXDOOeeauEZwm8AnHWogkipj0qE5MTHPeYn5putqn4Pi/gZlLe8tae/E56GSjq7LutREudXHOee+wycdciVYbGZdASRtDNwPtAX+WIf7/BXQ3syWZi3vDSwExtbhvp1zrnHyngGXBjP7FBgInKmgo6SXJU2Nr70BJN0raeVERTH97+HJWHH7QTGl8Kw4qx+ShgHrABMyy+LyjsBpwLmxpyIzdXGvmE743eRVuaQLEumEs9MbI+lYSdfE92dLeje+30bSK/F9N0mjJE2R9LykDokyz8XlL0vaIUf8P8WeAv/ddc6Vh0bQM+B/UMuEmb1L+PfYmJCp8EAz252QA2BwLHY7cTrhmJFwb1bPhngU0BXIpAEeJKmDmR1O7I0ws4cS+32fVemMu5rZy3FVB0JmxcOAK+M+DyJkDOwR99FNUnYWxNFApkGxH/C5pM1irJdjjoEbgKPNrBshd0Mm69YQQlKiboRkSTcnA0u6On4/J8WMh8l1K1MYP7P4ndW+X+ecqzMrVhT/KlN+m6C8ZDIZtgBujNn/KoHtAMxslKSb4m2Fo4BHY8rLpH2BBywkzv5E0ihgD7JyYhfhiXjCfTUmLIKQTvggQmpjgDaExsHozEZm9rGkNpLWJSQsup+QNnk/4DFCquLOwPCQaoAKYJ6kNoTGzcNxOUDLRH3+AEwws4G5KmtmQwiNCYZvclw6s5o451wxyviKv1jeGCgTkrYmnPg/JYwb+IRwdd8MWJIoei8h22E/4ORcoVKqUnJcgRI/rzCz2wpsO47Qg/EG8DKhnj2B3wJbAnPMrGdyA0nrAV9lxlHkMInQE7FBzOvgnHPlwccMuDRIak/oqr/RzIwwkHBevDL/OeHqOWMocA6Amc3JEW40cJykihi3FzCxQBWKTY/8PHByvIpH0maxlyJXHc6PP6cBfYClMaXyG0B7ST1jjBaSdo7pm9+TdExcLkm7JmI+R7hd8UzsdXDOufLQCMYMeM9Aw2ktaTrhlsAKwhX/NXHdzcCj8cQ4Avg2s5GZfSLpNeCJPHEfJ1yFzyBkDrzQzD4uUJengEfi4MTf5CtkZi9I2hEYF7vyFwInEHozkl4m3CIYbWaVkj4AXo8xlsUBiYPjuIfmwHWElMnHA7dIujh+Lw/G48js/+HYEBgm6YdmtrjAcTnnXN1rBD0D3hhoIGb5s36Y2VtAl8Si32XeSFqbcJ/+gTzbGnBBfGWvWy2tclz+Ztb+Xs5a3ybx/nrg+nx1j2XeIXG7wswOylo/ndBjkb3de8AhOZYPSLy/kzDo0DnnykMZX/EXyxsDaxBJfQknwmtil7tzzrmGVsZPCRTLGwNrEDN7kTAAzznnXLlIKS1zQ/LGgGt0ZrRMJ7f9qX3mlRzjX10uSaEmcOzMy1OJ889d06nPf4sab1pYZ9LJ9rbZ8nSuzOZXlP4ncdeW6XTafbaodSpx5jRbO5U4W1Sm8x23rkrnxFmZ2oNTKfAxA84551wT540B55xzronzAYTOOedcE1dZ2dA1KJk3BpxzzrlSNILbBD4DoctJ0u8lzYnZCadL2rOh6+Scc2Wpqqr4V5nyngG3mjhV8GHA7ma2VNJGwFoNXC3nnCtPjWDMgPcMuFw6APPNbCmAmc03s48kdZM0StIUSc9L6gAg6VRJkyTNkPRonCURScdImh2Xj47LWkm6S9IsSdMk9YnLB0h6TNJzkt6K6YqJORaGxjizJJ3bIN+Ic87lYVVW9KtceWPA5fICsIWkNyXdLGl/SS2AG4CjzawbYSbEv8Tyj5nZHma2K/Aa8Mu4/BLg4Lj88LjsDAAz2wXoD9wtqVVc1xU4DtiFkGxpi7hsMzPrHLe5K1eFJQ2UNFnS5PEL30rti3DOuYIawW0Cbwy41ZjZQqAbMBD4DHgI+BXQGRgeEyxdDGweN+ks6WVJswjJhnaOy8cAQyWdyqrMi/sSkjJhZq8D/wW2i+teMrMFZrYEeBXYCngX2FrSDZIOAb7OU+chZtbdzLrv1aZTKt+Dc84VpbKy+FcBkg6R9IaktyVdlKfMsZJejeO67k/jEHzMgMvJzCqBkcDIeJI/A5hjZj1zFB8KHGlmMyQNAHrHGKfFgYc/AqZL6grVThu2NPG+EmhuZl/GVMYHxzocC5xcwqE551y6Urril1QB3AQcCMwFJkkaZmavJsp0IiSv2yf+fcyVRr7GvGfArUbS9vEXLqMrofu/fRxciKQWkjI9AOsC8+KthOMTcbYxswlmdgkwn5jWOFNG0naEXAtvVFOXjYBmZvYo8Adg95QO0znn0pHebYIewNtm9q6ZLSOkcT8iq8ypwE1m9iWAmWWnkK8V7xlwubQBbpDUDlgBvE24ZTAEGCypLeF35zpgDuEkPYHQ5T8LVk5cPyg2KgS8BMwAXgdujb0NK4AB8YmFfHXZDLhLUqbh+rt8BZ1zrkHUIFGRpIGEv6cZQ8xsSHy/GfBBYt1cIPux7u1inDGE26+XmtlzNa1yNm8MuNWY2RRg7xyr5gO9cpS/Bbglx/KjcsRYAgzIUXYo4XZD5vNhidXeG+CcK181uE0QT/xD8qzOdVWU3dJoDnQi3I7dHHhZUmcz+6roSuTgtwmcc865UlRZ8a/qzSXcTs3YHPgoR5knzWy5mb1HuM1a8qhp7xlwjc7aKT3KO/G5jUqOsY7SGViUVurhE2akkwr5nb3PTCXOwMqlhQsV4Yyq76USp2UKeem/XZpOCu1uh3yeSpzKFH6PAa5vuTCVONs1Syf99f9sUSpxDkojSHq5CSYBnSR9H/gQ6Af8LKvME4THsofGMVXbEZ66Kok3BpxzzrkSWEpPE5jZCklnAs8TxgPcaWZzJF0OTDazYXHdQZJeJTx1dYGZldxy9MaAc845V4oUZxY0s2eBZ7OWXZJ4b8B58ZUabww455xzpWgEuQm8MeCcc86VooxzDhSrUT9NIGnDmH53uqSPJX2Y+FyWWfgknZeYq7/ocjFxUDojc5xzzhVvRWXxrzLVqBsDZva5mXU1s67ArcC1mc9xdicUlMX3EKeiPA8o2BjILmdmB5vZN3VVN+ecc3lYVfGvMlUWJ8H6JmnbmBL3VmAq0EHSkJj1bo6kSxJl50q6NKbbnRmn0EXSATE173RJUyWtI6mvpBGSnohJJG5SnFpP0gkxBe9sSX+Ny5pL+krSnyVNBC4ENiZMIvFiLLNavWIa3+xyc+OMgUi6MO5ntqTfZB3zHTHWv3P1QEjaRCGV8GRJEyXtFZffLOn/4vsfxeOUpH9KukUhUdGbkg5NHNs1McZMSafE5X0lvRT38YakexL7HhS/t5mSrqquPs45VzbSm2egwTTlMQM7ASeZ2WkAki4ysy8kNQdGSHokkRziEzPbTdJZhCvy04ALgIFmNkFSG8LMehCmjtyJMKXkcOAISZOBPwPdgQXAi5IOA54D2gJTzeziWI8zgP0Ss0nlqte1kn6bVY64fQ/C3P89CI+mTJQ0ClgEbA/0N7NZkh4DjiTMfZ00GLjazMZL6gg8TchWeAEhacZY4FpCamKLbZ0tgP0JE1+8KGlbQhrjT82sh6SWwHhJL8R97B6/o0/j8r2A94AfAjvHuO0K1Oc7lJjis3+7HuzrmQudc/UkrUcLG1JTbgy8Y2aTEp/7S/ol4TvZlHCyyjQGHos/pxBOWBDS816nkD7yUTNbGE+M483sfQBJDxJS9lYA/zGz+XH5/YRpfZ8DlgGPV1PP6uqVy36xPovivp6IdXiBkABjVuJYOubYvi+wvVblClhfUmsz+1bSacB/gN/Ema8y/mVmVcAbkj4gNAoOAnaU1C+WacuqWbLGm9m8WL/psR5TgCrgH5KeIZz0q6vP4mSlk1N83rzFCeXb/HbONT5lfMVfrKbcGPg280Yhmc7ZQA8z+0rSP/nuffvMNGmVxO/MzP4saRghPe8kSb1jmezfCqP6tL2L43OjqymiXjk3q2bdaimC82zfIzOmIssuwOeERklSvmP+tZm99J3gUt9c9TCz5ZK6E1J39gNOJzQoqquPc841vEbQGGiSYwZyWA/4BvhaUgfg4EIbKKTnnWlmVwDTCF3wAHtJ2lJhMOCxwCvAeKCPwtMNzQknu1F5Qn/Dqqx/1dUrWS5pNPATSa3j7YsjgJcLHU/Ci8AZiePsGn9uDZxFSGd8RDxxZxwTxw9sR7hl8BZhlqxfx+PNpEVunW+nCk9CrGdmTwPnArtVVx/nnCsblZXFv8pUU+4ZSJpK6HqfTZjjeUwR25wvaT9C1/ZMQjd8L2As8HdgZ2AkMCzeA78kfhbwlJk9kzlRZhlCuO/+AeEqOV+9VpYzs76ZhWY2UdIDhDmuAW6JYwS2LeKYIJx4b5F0EuH3Y4TC9Jh3Auea2bw4GPCOOD4BQorj0YRBjQPNbJmk24Atgemxi/9TVs/LndQWeCyOL2jGqtm1VqsPicaBc841NGsEPQPK00PtaiF2gZ9pZkc2dF3qS7x18YiZPdHQdclIa8xAp2XLS47xrSpSqAl8WZFOJ17ZJSr6trwSFaXxLW+hxYULFWHHAxekEieNhFvQeBMVPfLfYdXdWi3KN2cdVvTfnHUHP13y/uqC9ww455xzpfCnCVySmb1IuMfdZJjZCQ1dB+eca1CN4DaBNwZco3NA6y9SifNNVcuSY2xUkc4Vw39zjhWtubS697cZe2MqcXp2/30qcd5O6W9xKyu9B/cdrZ1CTaDqhXR6k3uevCKVOHPvWT+VOPdUfZJKnCuqymj2dW8MOOecc02bVfptAuecc65p854B55xzrmlrDI8WemPAOeecK0UjaAwUfKxWUqVCZr45Cln6zlNM+Supu6TB1WzbUdLP0qxwTUg6S9Jrku6r4/1cKunD+D29Kql/LePk/T4lvS8pnQeGa1anc6TiR0RJOiLmQ8h8/p2ktxOffxynca5JHRrk2J1zrihVNXiVqWLm2FhsZl3NbGfCjHg/BP4IYGaTzeysarbtCDRYYwD4NfBDMzs+uTDPzH+lutbMuhJm2btNUouaBiji+2wI5wA1GR49FuiZ+NyTMJ3yxvHz3hQ3wyMAcVpn55wrW7aiquhXuarRhFtm9ikhTeyZcS763pKeBpC0f7wyni5pWpxr/kpgv7js3NhT8LKkqfG1d9y2t6SRkh6R9Lqk+xTnsJW0h6SxsVdioqR1JVVIGiRpkqSZkn6VXVdJtwJbA8Pivi+VNEQhje49klpJukvSrFjfPnG7AZKekPSUpPcknRl7Q6ZJGi9pgwLf0VuEdMHrx3jbSHpO0pR47DvE5cdImh2Pa3Tie8h8nxtKeiHu9zYSCYgknRC/i+mSbsucMCUtlPSXGHO8pE3i8k0kPR6Xz0h87znjJPZzFiEp0QhJI+Ky/vE7my3pqhzH/xmwQKumP94MeJTQCCD+HFtdrHgcl0uaQKJhoZBv4TlJp1b3b+Ccc/WqifQMfIeZvRu32zhr1fnAGfHqeD9gMXAR8HLsWbiWMD/9gWa2O3AcIVd9xm6Eq9CdCCfxfSStBTwEnG1muxLS2S4GfgksMLM9gD2AUyV9P6uepwEfAX3ivgG6AUeY2c+I89ub2S5Af+BuSZmMgJ0JPRo9gL8Ai8xsN2Ac8Ivqvh9JuwNvxYYThBwCvzGzbvE7ujkuvwQ4OB7X4TlC/RF4Je53GGGefyTtGL+7feJ3XQlkej7WIaQH3pWQKyBz0hwMjIrLdwfmFIiT+Q4HJ77DPpI2Ba4CDiAkLNpDUq6pl8cCe0vanpC0aHz83BzoQsjyWF2sdYDZZranmb0Sl7UBngLuN7N/ZO9Q0kBJkyVN/teC/+WoknPO1Q2rsqJf5aq23eW5ZsMYA1yjcH/+MTObK61WrAVwo0LmuUpgu8S6iWY2F76T434BMM/MJgGY2ddx/UFAF0lHx23bAp2A9wrUe5iZZSYO3xe4IcZ9XdJ/E/UZYWbfAN9IWkA4CQHMIpzMcjk3XrFuDRwS69mGcCX8cOK7yMxkMwYYKulfwGM54vUCjor1e0bSl3H5DwiNmkkxZmtCIwtgGfB0fD+FcFsHwgn3FzFWJeHK/efVxMlnD2BkvPon/lv3ArLzEoyJx11BaEBNJDR+dgPeMLMlkqqLVUnoTUh6ErjazHKO/zCzIYSGF69v98Py/T/OOdf4lPEVf7Fq3BhQSGVbSThx7JhZbmZXSnqGMKZgvELSnmznAp8AuxJ6F5Yk1q2W457Q6Mj1h12Eq+3na1j9b7Ni5JOsS1XicxX5v7Nrzexvko4i3IbYhnCMX8Ur7+8ws9Mk7Qn8iJDZL1dq3nzHfreZ/S7HuuW2KvNU5jvMp7o41W1TjLHAbwiNgX+Y2Tex16U3q8YLVBdrSWy0JI0BDpV0f+IYnXOuwZXzFX+xanSbQFJ74Fbgxuw/yJK2MbNZZnYVMBnYAfgGvjOPalvClX4V8HPCyaI6rwObxqtI4niB5sDzwOmKg/QkbSdpnZocC6Eb/fjM9oRu+DdqGGM1ZvYY4fhPjD0Z70k6Ju5HknaN77cxswlmdgkwH9iimvodShyDALwEHK04IE/SBpK2KlCtl4DTY/kKSevVIE7y33ACsL+kjeL4gv7AqBzbvEoYa7AfMC0umw6cRhwvUINYGZcAn7PqNotzzpWHJjJmoHUcYDaHkITnBeCyHOXOyQyII9zX/zcwE1gRB62dS/hDfqKk8YQu+W9zxFnJzJYR7mvfEOMOB1oBtxNOOFMlzQZuo+a9HDcDFZJmEcYlDDCzdPKpwuVA5hHM44FfxvrPITxtADAoM3iOcOKfkRXjMqCXpKnAQcD/AMzsVeBi4AVJMwnfSYcC9Tkb6BOPdQqwcw3iDAH+LWmEmc0DfgeMiPWdamZPZm8QG4oTgPlmlskDPI5wC2VsLFNUrCznAK0kXV2gnHPO1RtbUfyrXMl7XF1jk9aYgW++LT1RUfOUEhWNTilR0cGt0knilFaiootTSlS0ntV4LHROaSQqWp5StvpeyxYXLlSELgNSCcPD97ROJc49Kq9ERXt99FjJ/2LzD92/6L85G/17VEq/IenyGQidc865UpRx93+xvDHgGp0Z36STarVLmy8LFyrgo6/TuXrpzPLChYowsDKdO2FppR7+8+S/pBLn+t0vSSXOshSu2XosSeff6nOtlUqcqk/npxLn2NPT6RnofkerwoWKsPVJ6dQnDZZiY0DSIcD1hDF1t5vZlVnrTyM8Gl8JLAQGxtu+JUmnb80555xroqyq+Fd14mDqm4BDCXPu9Je0U1ax+81sl/iU2tXANWkcg/cMOOeccyWwytSGAfQA3o6T+yHpQcKg85VX/pn5dqJ1yP0Ieo15Y8A555wrQU1uE0gaSJjWP2NInDQNwvTtHyTWzQX2zBHjDOA8YC3CpI+OfJ0AACAASURBVHIl88aAc845VwKrKr5nIDlbag65Aq125W9mNwE3KWQFvhg4segK5OFjBly9k/QTSaaYtMk559ZkaY0ZIPQEJCeg25yQHyafB4Fc+WFqzBsDriH0B14B+jV0RZxzrlRmKvpVwCSgk6Tvx0R9/QiJ6laS1Cnx8UeEZHAl88aAq1cxedM+hMyT/eKyZpJuljRH0tOSns0koZLUTdIohRTQz0sqNNuic87Vq7R6BsxsBXAmYcr914B/mdkchZTumey2Z8a/ldMJ4wZKvkUAPmbA1b8jgefM7E1JX8SUz1sTslTuQkiN/RpwZ8w9cQMh7fRnko4jpJQ+uWGq7pxzq6tK72kCzOxZ4NmsZZck3p+d2s4SvDHg6lt/4Lr4/sH4uQXwcExg9bGkEXH99kBnYHhMs1wBzMsVNDlC95T1etB37W3r7ACccy6pJgMIy5U3Bly9kbQh4TGYzpKMcHI34PF8mwBzzKxnodjJEboPdTjeE2445+pNY2gM+JgBV5+OBu4xs63MrKOZbQG8R0jh/NM4dmAToHcs/wbQXlJPAEktJO3cEBV3zrl8zIp/lSvvGXD1qT9wZdayR4EdCY/UzAbeJKQ/XmBmy+JAwsGS2hJ+X68jpIJ2zrmy0Bh6Brwx4OqNmfXOsWwwhKcMzGxhvJUwEZgV108HetVnPZ1zriaKeGSw7HljwJWLpyW1I0yv+Scz+7ihK+Scc8WoTPFpgobijQFXFnL1Gjjn3JqgMfQMyMp5RINztfCPzU9I5Zd6WvNlJcfotiKdnPSbLV+RSpwFzSpSifN2OodFy5T+iJ499fJU4ty22yWFCxXQssz+pM5uns7vzvaV6Vw7rl2DpD7VWZTS8Pdff/DPkn8JX9/uh0X/q+/w5rNl2XLwngHnnHOuBI3hmtobA84551wJ/GkC55xzromrrFrzp+zxxoBzzjlXgsZwm2DNb87kIelaSeckPj8v6fbE579LOq8G8TpKml1qmRrsb2gmc1+Odc0lzZd0RRr7qiuSbpO0T9ay1L4j55wrB1Wmol/lqtE2BoCxwN4QUuQCGwHJqWz3BsYUE0hSOkOw03MQYareYxUz+JSqjo5xT2B8HcR1zrmyYaaiX+WqMTcGxhAbA4RGwGzgG0nrS2pJmAJ3moJBkmZLmhXT5CKpt6QRku4nzoaXIWlrSdMk7ZFv55JaSborxpwmqU9c3lHSy5KmxlemwSJJN0p6VdIzhFS++fQHrgf+B+wVtz9U0r8S++8t6an4/iBJ4+L+HpbUJi5/X9Ilkl4BjpF0qqRJkmZIelTS2rHcNpLGx3WXS1qY2M8FcflMSZcllu8IvGlmlZK6xZjjgDMSZfJ9F/dKOiJR7r5ELm/nnCsrjSE3QaNtDJjZR8AKSVsSGgXjCHPe9wS6AzPNbBlwFNAV2BXoCwyS1CGG6QH83sx2ysSVtD1hPv2TzGxSNVU4I9ZjF8LJ+25JrYBPgQPNbHfgOGBwLP8TQsreXYBTWdWQ+Q5JrYEfAE8DD8TYAMOBvSStEz8fBzwkaSPgYqBv3OdkIHl7ZImZ7WtmDwKPmdkeZrYr8Brwy1jmeuB6M9sD+ChRl4OATvF76gp0k5SZOvhQ4Ln4/i7grBzZB/N9F7cDJ8V9tI3fxbNUQ9JASZMlTR797VvVFXXOuVT5bYLyl+kdyDQGxiU+j41l9gUeMLNKM/sEGAVkrvgnmtl7iXjtgSeBE+Kc+dXZF7gXwMxeB/4LbAe0AP4haRbwMJBpaPRK1OMj4D954h4GjDCzRYRGyU8kVZjZCsLJ98eSmgM/inXdK+5jjKTpwInAVol4DyXed45X6rOA41l1W6VnrCvA/YnyB8XXNGAqsAOhcQBwMPBcPJm3M7NRcfm9ie1zfhex7LaSNiY0dh6Nx5eXmQ0xs+5m1r3XOp2qK+qcc6mqrGpW9KtcNfanCTLjBnYh3Cb4APgt8DVwZyxTXVPt26zPC2KMfSicOS9f3HOBTwg9Ec2AJYl1xXQi9Qf2kfR+/Lwh0Ad4kXBiPwP4AphkZt/EMQXDzax/rmB89xiHAkea2QxJA1iVSjgfAVeY2W3fWRhuL7Qzs49ivoF8x1Xdd3EvoUHSDzi5QD2cc67BlHHvf9HKt5mSjjGEK+kv4hX3F0A7wpXuuFhmNHCcpApJ7QlX6BPzxFsGHAn8QtLPCux7NOFkhqTtgC0Jg/7aAvPMrAr4OVCRKN8v1qMD4QT/HZLWI/Q4bGlmHc2sI+HknznRjwR2J9xmyFzxjyc0HraNMdaO9cllXWCepBaZuidi/DS+75dY/jxwcmIMwmbxar4PMALAzL4CFkjaN26TjJvvu4DQMDknxvCUxc65suW3CcrfLMJTBOOzli0ws/nx8+PATGAGoWv+wuoy5pnZt4QGxrnJQW453AxUxC7wh4ABZrY0Lj9R0njCbYPMlfnjwFuxfrcQbldkOwr4T4yT8SRwuKSWZlZJGEtwaPyJmX0GDAAekDQzfhc75KnzHwjjKoYDryeWnwOcJ2ki0IHQQ4KZvUC4bTAuHucjhAZFcrwAhPv/N8UBhIuzvqNc3wXxls1rhPEGzjlXthrD0wSeqMgVFLv9F5uZSeoH9DezvA0hSVOBPc1seYn7nAXsbmYLarKtJyrKzxMVVc8TFeXniYrye/l7Rxf9r77fx4+UZYugsY8ZcOnoBtwYxx98RYF7+PHpgFqT1JcwpuOamjYEnHOuvlm1Q8/WDN4YcAWZ2cuEQX71tb8XCWMsaqVL1aJU6nHP8tLbIYetaJ9CTWB+RTr/q7ZMqSewVUpX9MtS+huaxhU9wK+mld7DcHW3P6RQE+iyNJ1L6Nkp/ZWvTCcMbarS+R38sqJ8TsAryrj7v1jeGHDOOedK4D0DzjnnXBOX0jCIBuWNAeecc64E3jPgnHPONXGNoWegsc8z4KqRTDgUPw+QdGN8f5qkXySWb5onRt51Kde1naRf1/V+nHOupipR0a9y5Y0Bl5OZ3Wpm98SPA4B8J/zq1uUUcyfUVDvAGwPOubJTpeJf5cobAy4nSZdKOl/S0YQsj/dJmh6zJmbKrLYupkSepJASekicmwBJIyX9VdIo4OxapEW+Etgm7mdQvX0RzjlXQBUq+lWIpEMkvSHpbUkX5VjfUtJDcf0ESR3TOAZvDDRtrePJdXrMaLjaQ9Zm9ggh7fHxZtbVzBYXWHdjTIPcGWhNmLo5o52Z7W9mf6fmaZEvAt6J+7kg3a/BOedqz2rwqo6kCuAmwpTuOwH9Je2UVeyXwJdmti1wLXBVGsfgjYGmbXE8uXY1s65AGjO39Imt1VnAAaxKgwzfTZdcm7TIeUkaKGmypMlPLHqvUHHnnEtNVQ1eBfQA3jazd81sGfAgkD31+xHA3fH9I8APMj2wpfCnCVxqJLUiJB/qbmYfSLoUaJUokp0SOmcYcqdF7ljdRmY2BBgCMGHTo8psdnjnXGNWVYNzsaSBwMDEoiHx7xfAZsAHiXVzgT2zQqwsY2YrJC0gpLKfTwm8Z8AV4xtCNsJC6zIn/vkxrfHR1cSsaVrk6urgnHMNprIGLzMbYmbdE68hiVC5WhXZFzfFlKkxbwy4YgwFbs0eQJi9DlgK/IOQbfAJYFI1MWuUFtnMPgfGxIGJPoDQOVc2UnyaYC6wReLz5iTGVGWXiU9mtQW+KPUY/DZBE2ZmbbI+DyWc3DGzSxPLHwUezRMje93F8ZVdrnfWog+BvRJpkScnyl5PGGCYHeNn1RyOc841iGKeEijSJKCTpO8T/kb2A7L/7g0DTgTGEXpf/2NWegYybwy4hlKjtMjOOVeu0hqkFMcAnEm4XVoB3GlmcyRdDkw2s2HAHcC9kt4m9Aj0yx+xeN4YcA2ivtMiO+dcXUlzMiEzexZ4NmvZJYn3S4Bj0ttj4I0B1+jsM39CKnFGbdCz5BjvVaTzv9iuLRekEufbpS1SifOO1k4lTo8ly1OJ826LdI7r6m5/KDnGhVP+lEJN4I0eZ6USp/+StVKJ81lKZ7wNtSyVOLa8VeFC9aQx5CbwxoBzzjlXgsoynma4WN4YcM4550rgPQPOOedcE+eNAeecc66Js0Zwm8AnHUqBpMo4Ic8cSTMknSepWVzXXdLgWsS8XFLfAmUulXR+seXTJmlQPOa8kwBJOjyTeStZX+ecayxSzE3QYLxnIB2LY6If4tS59xNmhfqjmU0mMaFOsZKPktRF+XwkNTezFUUW/xXQ3syWVlOvYYRJMuq6Ls451yAqG7oCKfCegZSZ2aeEJBRnKugt6WkASfsnUgZPk7RuXH6hpFmxV+HKuGyopKPj+/clXSVpYnxtm73fHOUvkzQ1xt0hLu8haWzc91hJ28flAyQ9LOkp4AVJ90o6IhH7PkmHZ+1vGLAOMEHScZJ+HLMVTpP0oqRNErFvzFHfkZK6x/cbSXo/V13isgskTZI0U9Jltf7Hcc65OpDidMQNxnsG6oCZvRtvE2yctep84AwzGxMT8SyRdChwJLCnmS2StEGesF+bWQ9JvwCuAw4rUI35Zra7pF/H/Z4CvA70irNc9QX+yqpkQT2BLmb2haT9gXOBJyW1BfYmTH+ZPMbDJS1M9Iisz6rphU8BLgR+W6CO+STrchAhhXEPQoKOYZJ6mdno5AbJTGCqaEuzZuvUctfOOVcz5dz9XyxvDNSdXG3AMcA1ku4DHjOzufGkfJeZLQIws3wJJx5I/Ly2iP0/Fn9OAY6K79sCd0vqRJhBMzlTy/DMvs1slKSb4i2Po4BHi+iu3xx4SFIHYC3gvSLqmM/wxPdwUHxNi5/bEBoH32kMJFMYN19rM09h7JyrN42hMeC3CeqApK0Jt5E+TS43sysJV+itgfGx+14UN7W15XmfT+Y+fiWrGn1/AkaYWWfgx6xKOQzwbdb29wLHAycBdxWxvxuAG81sF8JYgkLTg61g1e9fdtlkXQRcYWZd42tbM7ujiPo451y9sBq8ypU3BlImqT1wK+HEaFnrtjGzWWZ2FWFQ4Q6E++InS2F+12puExyX+DmultVrS8iEBTCgQNmhhDTDmNmcGsY+sbqC0fuEZEUQMm/l8zzh+2kDIGmz2GPhnHNlwccMuIzWkqYTut1XEK6qr8lR7hxJfQhX668C/zazpZK6ApMlLSMkqPi/HNu2lDSB0IDrX8t6Xk24TXAe8J/qCprZJ5JeA54oMvalwMOSPgTGA98vUP5vwL8k/by6upjZC5J2BMZJAlgInEBWr4tzzjWUxvA0gVJIg+zqWBxp393M5tfjPtcGZgG7m1k6WXLqSVpjBlJJVNQsnWQq5ZaoaGSLdBIV7VFmiYo+rSj9V6fcEhUtTC1RUctU4qSVqOjDgncii3PMvPtKvl7/y1bHF/2L8/v/lr6/uuC3Cdxq4qDG14Eb1rSGgHPO1TefdMjVCzPrWM/7exHYsj73mabrNumTSpwly0q/at24Mp05kz5b1DqVON0O+TyVOFUvpHNx87nSuWpNS5elpf+5TuuKfvuJNZ64NKc53c5JJc5wpdP7sijng1Y1972UhuMdk0KMxtC/7o0B55xzrgTlfMVfLG8MOOeccyVYoTW/b8AbA84551wJ1vymgDcGnHPOuZL4bQLnnHOuiatqBH0D/mihq3eSfi9pTsxCOF3Sng1dJ+ecq63GMB2x9wy4eiWpJyHj4u5x9sWNCImNnHNujdQYbhN4z4Crbx0I6ZWXApjZfDP7SNIPJE2TNEvSnZJaQph9UdJlkqbGdTs0aO2dcy5LJVb0q1x5Y8DVtxeALSS9KelmSftLakVIjHRczHrYHDg9sc18M9sduAU4P1dQSQMlTZY0eczCt+r4EJxzbpXGMAOhNwZcvTKzhYRshQOBz4CHCCmP3zOzN2Oxu4Feic0eiz+nAB3zxB1iZt3NrPs+bTrVRdWdcy4nq8F/5crHDLh6Z2aVwEhgpKRZFE55vDT+rMR/Z51zZaacr/iL5T0Drl5J2l5S8tK9K/AJ0FHStnHZz4FR9V4555yrhSqs6Fe58qssV9/aADdIagesAN4m3DJ4AHhYUnNgEnBrw1XROeeKV76n+OJ5Y8DVKzObAuydY9VLwG45yndMvJ8M9K6rujnnXG2sqKfmgKQNCOOsOgLvA8ea2ZdZZbYijLOqAFoQUtEXvLjy2wTOOedcCepxAOFFwEtm1olwAXVRjjLzgL3NrCuwJ3CRpE0LBfaeAdfotF+RTiu9Y/uvSo7x2RfrpFATmNNs7VTiVD63USpxep68IpU4VZ/OTyXOH17aMJU4s1P4i9h/STpzaM3pdk4qcXaecl0qcS46/JepxHn73XR+BzttOy+VOGmoxwGER7Cqd/RuwkDs/5csYGbLEh9bUuRFv/cMOOeccyWoSc9Ack6U+BpYg11tYmbzAOLPjXMVkrSFpJnAB8BVZvZRocDeM+Ccc86VoCY9A2Y2BBiSb72kF4Hv5Vj1+xrs4wOgS7w98ISkR8zsk+q28caAc845V4JKS28AoZn1zbdO0ieSOpjZPEkdgE8LxPpI0hxgP+CR6sr6bQLnnHOuBPU4z8AwVk3SdiLwZHYBSZtLah3frw/sA7xRKLA3BtYgaaT+ldRd0uACZXpLerqIWCMldc+z7nZJOxXYfqikowvtxznnylk9Pk1wJXCgpLeAA+PnzN/122OZHYEJkmYQJm/7m5nNKhTYbxOsIdJK/Ruf1Z+cdv2SJFWY2Sl1vI/mZpbOkHbnnCtBfT1NYGafAz/IsXwycEp8PxzoUtPY3jOw5siZ+hegmvS/e0gaK2mGpImS1k1e9UvqEddPiz+3r64CklpLejD2TDwEtE6sWyjpckkTgJ7JXoO47i+xHuMlbZIj9p9iT0EzSd0kjZI0RdLz8d5Ypifir5JGAWen8aU651ypGsN0xN4YWHOslvoXIF/6X0lrEWaqOtvMdgX6AouzYr4O9DKz3YBLgL8WqMPpwCIz6wL8hZB9MGMdYLaZ7Wlmr2Rttw4wPtZjNHBqcqWkqwmPyJxEmDXrBuBoM+sG3Bn3ldHOzPY3s79nxVj5uM6Li94ucBjOOZcez1ro6o2ZLZTUjTAqtA/wkKSLgGmsnv73DMLsVPPMbFLc/msAScmwbYG7Y+IgI0xdWZ1ewOAYb2Z8jjWjEng0z3bLgMwYhCmEe10ZfwAmmNnAWL/tgc7A8FjXCsKMWhkP5dpB8nGdhzocX77/xznnGp00nyZoKN4YWIPkSf07PU9xUTh/xp+AEWb2E0kdY+yC1cizfEmsXy7LzVb+35KdhngS0E3SBmb2Raz3HDPrmSfWt0XU0Tnn6k05d/8Xy28TrCHypP79L6GrP1f639eBTSXtEbdfN2YETGoLfBjfDyiiGqOB42O8ztRikEoOzxFGxD4jaV3CIzDt44BJJLWQtHMK+3HOuTpRVYNXufKegTVHztS/ZrZE0klkpf81s2WSjovbtCaMF8iezOJqwm2C84D/FFGHW4C74u2B6cDENA7MzB6ODYFhwA+Bo4HBktoSfkevA+aksS/nnEtbOY8FKJY3BtYQ1aT+xczypf+dBOyVtXhkfGFm44DtEuv+EJevLJMVbzHQL08d2mR97p1rnZk9QpwJy8wGJJbfSRgsCKGh0SvHPnpnL3POuYbWGG4TeGPAOeecK4H5AELnys+6VfnGMdbMh/PXSyXOIqsoOcYWlenMr3R9y4WpxJl7z/qpxDn29NaFCxVh+3T+yUkjzKSK5nRcXnqk4Sr0cE9x0ko93H7YHanEWee3pxYuVITWlw1KJU4aKr1nwDlXnTQaAm7NkkZDwK1Z/DaBc84518T5bQLnnHOuifOeAeecc66J80cLnXPOuSauMUxH7DMQuqJJulbSOYnPzydyaCPp73ECo3zbjy1iH+/H9MzZy3tLyjnPgnPONSTPWuiamrHEiY8kNQM2ApJTBe8NjMm3sZmVcjLvTZ5Jl5xzriF5Y8A1NWNYdULeGZgNfCNpfUktgR2BaZIukDRJ0kxJl2U2lrQw/mwW0zDPkfS0pGclHZ3Yz28kTZU0S9IOMYnSacC5kqZL2q8ejtU554piZkW/ypU3BlzRzOwjYIWkLQmNgnHABKAn0B2YSbiC7wT0ICRT6iYpe2rho4COwC7AKXH7pPlmtjshF8L5ZvY+cCtwrZl1NbOXs+smaaCkyZIm/3vxOykcrXPOFcd7BlxTlOkdyDQGxiU+jwUOiq9pwFRgB0LjIGlf4GEzqzKzj4ERWesfiz+nEBoNBZnZEDPrbmbdD229TU2PyTnnas1q8F+58qcJXE1lxg3sQrhN8AHwW+BrQqKh3sAVZnZbNTFUYB9L489K/HfUOVfmKq2ckxMXx3sGXE2NAQ4DvjCzSjP7AmhH6OofBzwPnCypDYCkzSRtnBXjFeCncezAJoQGRCHfAOumdAzOOZcaHzPgmqJZhKcIxmctW2Bm883sBeB+YJykWYR0xdkn8UeBuYSehdsI4w4WFNjvU8BPfAChc67cNIYxA94F62rEzCqB9bKWDcj6fD1wfY5t28SfVZLON7OFkjYEJhIaFJhZx0T5ycReAzN7E+iS4qE451wqynksQLG8MeAaytOS2gFrAX+KAwmdc26NU1XG3f/F8saAaxBm1ruuYk9plU7a4K1WlP6/R4uU/ki0rkonznbN0hl2cU/VJ6nE6X5Hq1TirF3VNpU4bVL4njfUshRqAosKjrMtztvvrjahZ62s89tTU4mz9t//kUqciZ0vTCXOPh8/UnIM7xlwzjnnmrjG8DSBNwacc865EvhtAuecc66J89sEzjnnXBPXGHoGfJ4BVyuZpEOJzwMk3Vhgm8MlXVSgTG9JT+dZd46ktWteW+ecqzv1NR2xpA0kDZf0Vvy5fp5yW0p6QdJrkl6Nyd6q5Y0BV2/MbJiZXVlCiHMAbww458pKpVUW/SrRRcBLZtYJeCl+zuUeYJCZ7UhIGvdpocDeGHCpk9Re0qMxjfEkSfvE5St7DyRtI2l8XH95Vk9DG0mPSHpd0n0KzgI2BUZIyk5s5JxzDaYepyM+Arg7vr8bODK7gKSdgOZmNjzWbaGZLSoU2BsDrrZax6mBp0uaDlyeWHc9Id3wHsBPgdtzbH89cH0s81HWut0IvQA7AVsD+5jZ4Fiuj5n1yQ6WTGE8eeHbJR+cc84VqybTESf/VsXXwBrsahMzmwcQf2bnfQHYDvhK0mOSpkkaJKng5Cs+gNDV1mIz65r5IGkA0D1+7AvsJK2cNGU9Sdmz3fRkVav2fuBviXUTzWxujDudkMb4leoqY2ZDgCEAf9rq+DV/NI9zbo1Rkyv+5N+qXCS9CHwvx6rfF7mL5sB+hIuq/wEPAQOAOwpt5FzamgE9zWxxcmGicVDI0sR7T2PsnCtraT5NYGZ9862T9ImkDmY2T1IHco8FmAtMM7N34zZPAHtRoDHgtwlcXXgBODPzQVLXHGXGE24hAPQrMq6nMXbOlZ36epoAGAacGN+fCDyZo8wkYH1J7ePnA4BXCwX2xoCrC2cB3SXNlPQqcFqOMucA50maCHSgcApjCF1r//YBhM65clJpVUW/SnQlcKCkt4AD42ckdZd0O6zMLHs+8FJMIy+gYEII7351tZJJR5z4PBQYGt/PB47Lsc3KMsCHwF5mZpL6AZNjmZHAyMQ2Zybe3wDckNYxOOdcGlJ4SqDY/XwO/CDH8snAKYnPw6lhyndvDLiG0g24UWEgwVfAyQ1cH+ecq5XGMAOhNwZcgzCzl4FdG7oezjlXqvrqGahL3hhwjc4BS5cWLlQEqfT/wRdXpfO/WGVKue3/V3jukaJcUZXOOM6tT2qdSpyXC94RLc6XFaV/z7a8VQo1ge+llPym07bzUonT+rJBqcSZ2PnCVOL0mH11KnHSUOWJipxzzrmmzXsGnHPOuSYuhacEGpw3BpxzzrkS+ABC55xzrolrDLcJfNKheiKpMib1mSFpqqS9a7j9UElH11X90iDpcEn5Umrm26bsj8s556pTjzMQ1hnvGag/KxP7SDoYuALYv2GrlC4zG0aYLtM555oM7xlwtbUe8CWAgkGSZkuaJem4xPIbJb0q6RliqkpJP5D0eCaQpAMlPZa9A0nvS/qrpHExTebukp6X9I6k02KZNpJeij0VsyQdEZevI+mZ2IsxO1GnK2N9Zkr6W459DpB0Y3w/VNJgSWMlvZu5+s93XHFdN0mjJE2Jde0gqbmkSZJ6xzJXSPpLGv8IzjmXhiqzol9ly8z8VQ8vQva96cDrhHn4u8XlPwWGAxXAJoSUkx2AoxLLNyXM0nc0YZ7p14H2cfv7gR/n2N/7wOnx/bXATEKSn/bAp3F5c2C9+H4j4O0Y/6fAPxKx2gIbAG8Aisva5djnAODG+H4o8DChwbkT8HZcnu+4WgBjE8d1HHBnfL8z8BphLu5pwFo59j2QMKXxZGBgEf8eBcsU+e/qcdaAungc/zf3V/Uv7xmoP4vNrKuZ7QAcAtwTp+LdF3jAzCrN7BNgFLAH0Cux/CPgPwAWfsPvBU6Q1A7oCfw7zz4zXfazgAlm9o2ZfQYsidsK+KukmcCLwGaEBsksoK+kqyTtZ2YLgK+BJcDtko4Cipm95gkzqzKzV2Nc8h0XsD3QGRguaTpwMbB5POY58ZifAk42s2XZOzKzIWbWPb7y5gpPGFhEmWJ4nLqN4XHWrDjlVJc04zR6PmagAZjZOEkbEa7Sq5vyLF+f0l2EE+MS4GEzW5GnXGYqvqrE+8zn5sDxsQ7dzGy5pPeBVmb2pqRuwA+BKyS9YGaXS+pBSJLRj5Ci+IACh5rcZ/I4cx2XgDlm1jNPrF0IvQib5FnvnHOulrxnoAFI2oHQTf45MBo4TlJFzD/dC5gYl/eLyzsAfTLbxyvqjwhXz0NLqEpbwi2D5ZL6AFvF+m0KLDKzfwJ/A3aX1AZoa2bPEtIPd63lPvMd1xtAe0k9Yx1aSNo5vj8K2JDw3QyOvRrOOedS4j0D9ad17P6GcBV8oplVxsGAgk9b3wAAIABJREFUPYEZhCvmC83s47j8AEKX/ZuE2wdJ9xHur79aQp3uA56SNJlV4xkgXIUPklQFLAdOJ4w3eFJSq1j/c2u5z5zHZWbL4iDDwZLaEn43r5P0CSFn9w/M7IM4QPF64MRa7j+jmFsJHqfhY3icNStOOdUlzTiNXmYwmFvDxJPiNDO7o6Hr4pxzbs3mjYE1kKQpwLfAgWaWToo+55xzTZY3BpxzzrkmzgcQOlcmJLVsyvt39ScO4K3tuB/XCHljwDUJkraLsy3Ojp+7SLq4lrG2ktQ3vm8tad1axLgz63Mb4Nn/3955h9lVV+v/8yb0EgQpojQBARFFgnT0hyAoCliwgCAKtqsUI/Z2RfRauIoFBQEVEQUVES9NQJDeCYTesYsCItL7+/tjfU9yZjKZnL3PzuyZnPV5nvNk9p7slTUlZ6+9yrvq+NMvkjaWdB1wWzleX9IhNey8e4RzX23AxVaR9LVezvVoa0tJe5aPl5P0/H79q4Ptp4HXN2FL0ha9nBsLJH1R0gJdx1MkHdWGLxONDAaSQeFI4FPEdAS2ryX0Eioh6b3Ar4DDy6mVgN/U8Odvkg4rNpcGzgR+WsOfD5U3PEn6YZGW3q6ime8AOxCjrti+hq5R1gq8WdJuXb4dSuhYVELSCuVr+W05XnekQGMM2XaEc9tXNSLp88AniN9DCNXNOj/ztSQdKelMSb/vvKraAS4q0uAvV8iVT5U0tYadkQLHOsHk2b2cmwsLAJeVYH874ApgelVfBpEcLUwGhcVsXx6ijzOZk1jTaOwNbAxcBmD7NknLj37J7Nj+XFF4/D6wIfBV2yfU8Gcv299WLL9aDtiTEKU6s4KNSbb/NOx783QNX94EnFRGUrcH7rP9wRp2fkx8DZ8px7cCvwDGdHJG0geADwKrF5XODksCF9Uw+UZgA+AqCL2QOlklQub7+0SAW+fn1KGzOfXArnNm7mJiABRNkM0JfZD9uz41hdBR6YkyrrwYsGwJjDu/iFMIyfKesf2pEkBcRux/eYXt26vYGFQyGEgGhXslrUFRPyyaBnfVsPN40USg2FmAOStFzkYRUOpwOfC58qclvcn2bEun5may/Pla4Cjb12jYXb0H/lLUJS1pMrAvcQPuzQFpma7D9xCZkouAAyUtY/u+iv4sa/uXkj4FYPspSZVvepJ2AE6z/UzVawvHElLfXwG6V3M/WONrAnjCtiV1fgcXr+nXU7YPq3ntTGzXyf50sxCwBHEf6Q5qHiD2jfTK+wkhs+cST/Gd398HgO9VcUjSKwgdkgMJvZTvStqrCLUlo5DTBMlAIGl1QoBkc+KJ4Q/A7rb/WNHOQYQs8h7ETfODwI22PzPqhbOuH61+adt7VfTnKGKnxPOB9YknsnNtb1jBxvJEqeBV5dRZwD627+3x+j8wNCAaIj1te/VefSn2zqUs8LI9VdKmwNdsV1r5LemnhKDXCUSgdFOV64fZ2hJ4ge2jFFLiS9r+Q0UbHwVeQJQdvgLsBRxru1JKXdIBwN2EgNfM0eKqAYqkFYAvA8+1vb2kdYHNqmqXSFrV9p+qXDMHO/tW/V6MYONy4F0dMbYSfH+57IRJRiGDgWSgKE9jk2w/WPP6ScC7ge2Im94ZwA/c0n+k4s9LgTtt3y/p2cDzSk/EWPuxme066fPhtqYSNef1gOuJ8seb63xNkqYAuxLlExPlh+Oq/PxLrf9lwNq211LIdR9vu3KTnKRt6frdsf27GjZGCkLqBF2/pZRjbK9fslxX235xRTtrAR8FVqMr22y7p3LDMFubj2DnJxWun1yaI7vPPdv2v6r6MmhkMJAMBJK+DBxk+/5yvDTwEduVJgpKMPFY5w2npNUXtt3LFsduO2sBhwEr2F5P0kuAnWx/qYqdYut5xF6J7jfQ8ytc/xXiSfUR4BSirv1h28dW9OOSURZNVaLcmNYmbpq32H6yD1vLArsTqeibgDWB7/T6FKqQEd8AuMr2BuXctbZfUsGHycTN/1Vz/ctjhKQrbG8k6equr2uG7Up7RyRdQ/QwTKerh8F2pcY9SccAaxDS6B07tr1fBRudbMfzbL+mbrZjEMmegWRQ2N72pzsHtv8t6bXEsqcqnE2k0x8qx4sSzXqbz/GKkTkS+BhlKsH2tZKOBSoFA4oRt7cBN9L1BkoshOqV7Uvj1RuAe4gn8rOImnkVzpS0M/DrfjIlw/oqANaS9B/gOtt3V7CzI5GKX4NYgb2x7bslLUYEBb2mpPuu9Zc9JI9IWsqxErw2khYk9oW8opw6Fzi8RsD0cMkkdb6uTYE6vjXSw0BkX9btM8v2Y8ZB8+lEJIOBZFCYLGnhjnyzpEWBOiI7i9juBALYfqjcXKrS1HTDG4j0dT+y1J33gdcSKfR7Oje+iuwPLA48LelR4qnetqdUtPNuotZ/TjneCriUCAoOtH1Mj3beAnxzeJbE9iOSqvRm/FLS4cCzFKOlexHBXFUeA66T9DtCTrzjT89PvoXDiLHEQ8vxO8q591S0sz9wErCGpIso5ZheL+5qHD1Z0gfps4eBKAk9h3qNvR0aaT4dRDIYSAaFnwJnl4Y7E2/oR9ew87CkqbavApC0IfBoDTtNTTfcSdwY+gkGfqsQY3oa2Luk1Svbs11nTG4kngFeaPufMDP1exiwCZHx6CkYsL3HKJ/reX7d9tdLrf8BonTx33Vq/cCp5dUvG9lev+v49yVVXwnbV0n6f3SVY6imPTOd+P3tRLQf6zYP9NTDIOnk8veXBG4sTYDdQcVOFXxqKtsxcGTPQDIwSNoe2IZ48zrT9hk1bGwE/BzojCqtCLytRn20qemGE4gpgrMZ+gZa6WmzTBTcV56kFgeeZftvVWwUOzvRlb62fUoNG9d1N7GVUcnrSm/FzPp2D3Y2JUoBLyTG4CYDD9fIVIwrJF0FvMX2HeV4deBXtisJBkn6Uff0Svm5n2R7m0Ydnrsfo06J2B6+vn00W401nw4aGQwkSUVKzbbzNHVzn81t/U43vHOk87YrZT0UOgOrMbQJsWoD4VeBjYCflVO7AtNtf3LOV41o51BgFUJcB2LM8K/Ek+cp7nE+XtKVhMrk8UQ9eg9gTfc4Btpl50Fm15L4D3Al0YR6Z492ho9gAlBjCmAboi7e+XdXA/a0fc4cLxrZzheJtPoHSkPtqcCRtivJ947Q4wHx/anU49EUTTafDhIZDCQDQXnD+hqwPPEmUbee3ff4U7HRyIx3sbUQsFY5rPzmJ+nHwLrM3sVdST1QodL3UheRn9JBf3WVrvtynQg1wy3LqX8BK9reu6KdK22/rLvzX9LFtis1e0r6ApEJOpb4vdmFqG3fAnzA9lY92nl21+EiRE/DMrb/u8frNwL+YvsfiqVS7yeaWf8BfLJGjb7TgLoUfahgSjqVOfR4AD33ePQTdM0hIJmJq4t5DRzZM5AMCgcBO7oP4RmY8/gTUCkYoKGuZ0lbEb0PfyRuVCtLemeV0UJgU6KLu65SXzfPAjo3paXqGCid+3cQPQJvJUoodaSaHymB0gyFWNRdRINjVV5je5Ou4yMkXWr7QEmfnuNVw/Dss+7fknQh0FMwQEyedEYTNyFUEfcldCaOoMfmPzWvgtlIjwdwMHMOun5EBBlzYsfy5/JE6a2zq+GVxLRFBgNzIYOBZFD4Z7+BQKGJ8Sdoruv5G8B2tm+BmfoFxxFPer1yA7AsoWrXD18BrpZ0DvFm/gpmLeWZK8X3XYjywr+I4Ei9lgVG4B1En8A+wIeBlYmSQ1WekfRWYkEVDL3pVpGi7q7pTyJ+l6o0XU7uevp/G3BEeZI/QaGF0Cs7Dju+mmhC3ZH4eqreOFfrBAKFu4G1bN8nqUqWqnbQZbuzCfIU4v/nXeV4RSpKGg8qGQwkg8KVkn5B6OZ3N9pVfeNrYvwJmut6XrATCADYvrX0NFRhKeAmSZcy9Hszaup1OLaPU0gJb0QEA5+w/Y8KJm4GLiAyOLcDSPpwFR+G+dORyH0U+EJdO8BuhN79ocTP61Jg9zKeuk8FO9/o+vgpIpvz1grXT5a0gO2niEbY93V9ruf38s6Ns0EuKDfh7h6P80s/zP0V7DQRdK3WCQQK/2RWCS0ZhQwGkkFhCqGw173et85T0LL0P/4E8BH6mPHu4kpJP2RWKnZ3qq9s/UqNf3cmkv4PuBC4GLjC9kk1Te1MZAbOkXQ6MbVRdekSkq5jlJtHlR6G0vfwetvDn6Y7XNirrT4yHB2OA86TdC8R4FxQfFyTGoGkpOWA9zJ7/0ul/RjEJs+dgS2In9dPgBNK9qzK19xE0HWupDOI75Upv08VfBhYsoEwSSowpzGoKuNPXbb67noujWR7E812Imq0h1YVIZK0ErGI5xzFStnJth+e23Xl2h2IOu3mwEuIJ/yLiODg4mEp5F7sLU6IKe1KrNM9GjjRdk9rmSWtWj7sNBx2AqXdgEdsHzj7VaPaO7fXJsE5XL//aJ+3fXAFW5sS46xndn4+pbyyREf7ooKti4mAYriMcJ3+jHFD6Yl4eTk83/aJbfozUchgIBkI1OwugFWJG+dZCvXByVVHAyVdQNy4LwAuqjtaOMzmMsBKVWeqFWp8+wBL2V6jfK8OdQ0d/fIkvQHR7PVfwPNt97zbfgR7yxBd929zxcU3ki7ysGVCI53rwc7/EKWUXzBUObCnm69i0dEcsd1PCaM2qrGHYNj1F9recoQpgEqTOpI+bvsgSYcwQkbH1RUakxpkMJAMBJLOo+wC8KylLNfbXq+infcStdplyo3zBcD3qwq1FKGYLYknmE2JksMFtivVyEuNficizTuD2C1wnu1Rn0aH2ZgBbAxc1vW9GSL804ONZZmVHdiUGJ2bAVxSVfOgKcrXtY/tC8vx5kSQU3URz0hpZlcNTsYbkr5EZG5Oa9mPHW2frAY0M5ocIR40smcgGRSa2gWwN+XGCWD7NoV6XyVs36nQ73+ivF5JKOVVZSnbD0h6D3CU7c+Xef8qPGb7ic73pjzd94yk24ia9QnESucvuWt/Q4u8G/iRpKWIJ87/EDLUlei31j+On3w/BHxa0uPAk/SnvbElkS07qgSGS9oeadXybNg+ufx5dLG1eK8lqhFoZIR4EMlgIBkUmtoF8PiwG+cC9N7pPJMyR38vMVP9Q2DfmnP+C5TxqbcyS7OgKhdJ+jiwiKRXEgFPFRnhHxHZgJ2BFwPrSbqEEBwa8yUxkjYDLnVIRK8vaQqRBa2tUS/pdcCLiIwHABV6Dzo3pivr/vvzAje0S6KUQV5G9L8cRUg//5RoKKxiZzPi/8ISwCqS1gfe72riV02NEA8cWSZIBgI1twvgIGJcag9C8OWDwI2uLnH7IaJMsDLRcHce0ex0R0U7byFEYy60/cHydf6v7Z7n6Usm4H3EpIWIp/vD6wQnpd9gc0KR7uXAPbZH1Z5vGknfJ7I3twKnA6dXHHEcyd5iRPbmB8TUx+W2392Au2OOpHVs3zxM92AmNRoRZxB9Ild1lZlmqj5WsHMZ8b09qW4pT9K3idHffkeIB44MBpKBQv3vAphEpJ+7b5w/cM3/SJKWAPYEPko0/9VutuuHok3wAiLLcVuZZa9qY3UiENii/Plcog9hhyZ9reDPOsD2wKuJBsBziODgoioZi86NrevPJYBf295urhcPtbMc8AlC+rk7wzCmvQeSjrD9vqZ6ISRdbntjSVfZnlr+j11SJxiwvYm6llFJusZDNzTOzcZIexVcY1xy4MgyQTIQlCfxo4AHgSPLU9Enex1X61Celo8sNjrd+3XKBN8gMgNLAJcQkrQX1LCzCBGcDE9h9/zmJ+k1RNbkz0SAs5Kk91YY5TuRKBP8h/haLgIOsX1jrz7MC2zfTGRdvllm1V9JTCYcTKS1e6WzovoRSc8l1BGfX8OlnxETCa8jJi3eSTR8jiklEJgEfNb2RQ2Y/KWkw4FnlQbbvYj/I1X5S2nytEJGej9mlVh6ws0LKg0MmRlIBoLOE4akVxM18c8RDXdV176eS5/d+8XOW4iyQKUZ/BHsHE/c8N4OHEjM0t9k+0MVbNxMjFneWo7XAv7Pdk8NjYq1xRfbvreq//OaYY1tyxHz+D01tnXZ+ByxFncbQtrWRDbocxXtTLe9oYYuTjpvrMsoXf5cYnuzPq6fRgR+VxOB1sxsme3f1bC3LCE69Kpi50zgQ559p8NI147XJs0JQ2YGkkGhM0bwWiIIuEbDRgt6pInufWwfP/e/1RNr2n6LpNfbPlrSsUTpogp3dwKB4tutknp+YnV9xcF5ygiNbQtSo7ENOMgh4nSCQnZ3EeCxGi51RKXuKg2JfwdWqmGnKc6UtDNR8qjzVLgScfNeB7iWEJm6iOoKmACUYHK3OtcyTps0JxIZDCSDwnRJZxLp3U9JWpLYtlaVJrr3m6Rzg7lf0nrEOtvVKtq4XtJJwC+Jp6q3AJeXJ/5xe7PvgTdSGtsAbP+9/Nyrcgkwtdh4HHhc0lWdcxX4Uhlz/AiRaZhCLFBqi/2JLY5PSXqMiqOFtj8KUFL6LyP6RPYiSmj32163Fztzeprv+nfm+lQ/fDwxqU4GA8mg8G5i1eudth9RLAmqU188kHjyvsj2FaVp7rYG/azKEZKWJsoeJxE9CL2uxO2wJFHvf3U5fhBYgQgKXOxORJ6wbUmdcdJK64slPQd4HrCopA2YlV2aQkwX9Grna7Y/ASxaxhv/QzXN/nlCU6OFwKLE92Sp8vo7cF2F67uf5r8AjKrYmMwbsmcgGRgU6mRbEje4C92yZnkT9ex5haQFXW9Xwk7E6mKIXoqTm/Wski8fJSYktiWWMe0FHGv7kB6vfyfwLuKp9wpmBQMPAEf3Oq6mWJw0lZisqJpNaJw5jRR26HW0UNIRROPqg4QI16WEvsO/+/Bt5iRBMrZkMJAMBJIOBdYktplB7IO/w/bec75qRDurE3XSTYmg4hJgWo2mtJn1bNtrlS71411dN38F4MvAc21vL2ldYDPbP6xg42xgT9t/LsdTgR9WfVOW9BVivv9n5dSuwJW2P1XFTpNI2pb+G9t2dh/LeyT9L6HjsDixOXPmp2hBKrdrpHAR4nfwmuLLS4iAZcse7ZxObPG8nugXuAS4vu6YbbF51XgImAYS2/nK13z/Am6gBL/leBJwQw07lwLvIEpsCxArgy+rYWcG8QZ8dde5a2vY+S3Rv3BNOV4AuK6ijdcBtxA3rC8QN4eNavhyLaHh0DmeXOdrml9fxIRG6350+fNz4MVdx+sBP65oQ+W69wE/JlL+ZwJfqOnTVX1+TQcRJYsFgbMJlc/d2/5eT4TXpL6jiSSZGNwCrNJ1vDJx86qKbB9j+6ny+ik15Igp9ezOtVXr2V0sa/uXlGZIh1hQJQlg26cSb+bfK39uZ/uKmv48q+vjpWraaARJD0p6YNjrL5JOLBmeMcX268f635wL69ieWdu3fT3RV9MzDq4HTiMC04uANYi9Bz3R/XMCXtL1s3qwnKvCdrYfAHYA/gqsRSwoS+ZCNhAm8zWSTiZuuEsBN0m6vBxvQqQ2e7WzTPnwHEmfJJ6qTJQbTq3hWlNCLQ+XZshOUNER/+kZSZ8iRrq2JlLF50qaZrvqiOJXgKtLGlpE78CnK9pokoOJZrZjiz+7EFK1txD7FLbqxYikhR1TBKOem4DcJOkHxLiliSxXzyI/kvZjluLkk0QgcAnxve25gdDNNTJCZAQgRoiPs31fvQniwSN7BpL5GkmjCrrYPq9HO38g3jBHemex7cpPmg3Vs6cSY2rrEbXb5YA32+456yHpe8DHbD9SjlcnegYqd7yXscuNiK/pMvexE6BfVORth5271PamqiBzO1Ide36obSvUKz/ArIbP84HDbPekoSDpYIq2gO06S78aR9JXgTcQqpEbE5mqU4b/HiSzk8FAkkxAJG0E/MX2PxSbE99PbA28Efhv2/fVsNnX066ks21vM7dzY4Vic+I3gV+VU28G9i/BwAzbo6bEu0YLf0ooPHaPFn7f9joV/dkBOM31tlMmPVJGbR+w/bSkxYApbQalE4XsGUgGAkmbSrpC0kOSnpD0dI16ZMfWepLeKmmPzquGjTdJuk3Sf2rWRw8Hnigfb04IIH2P2Mh4REVfNi7jb7eV4/WLEEyv1y9SyijLSlpa0jLltRqxrKgtdiOaPe8G/lk+3l2xp2CfHq5/NfB1QmnvYOAb5bU/9cofuwC3STpIUk9Sz0k1FDLfT5VA4LNEINfm7+CEITMDyUAg6Urizfh4YpxqD2LGv9KbehkJ3IrYPHcasRXvQttvrmjndmBH19y93p3mLmn+e2wfUI7n+tQ7zNalRO/Db1xjdaxiCdQ04k33bwydxz/S9nd79WU80u9o4TBbU4iRyz2JstNRRG271hbNZCiatVlyS6KH5evAp7NMMHeygTAZGGzfLmmyY33tUZJ6biDs4s3A+sRI4J5lzv8HNez8s24gUJgsaYEyPbANMQXQoer/60m2/zSs0arniQTb3wa+LWlf9yjoMxaoz42OknYv0yKrSZptEZXtg6v65NhrcQKh2jeNkEz+mKTvjKfv3QSm83v7OqL/4f8kHdCiPxOGDAaSQeERhYb6DEkHAXcRIjBVedT2M5KeKk95dwM9Nw8qVBABrpT0C+A3wMw6vXtUtSPEk86TdC/RLHVBsb8mFacJiNWxGxOrYycD+wK3zuWa2RiHN7NjiI2Or6Zro2OF6zu/H0s04YxCnXFPYvTuGGBj23eXuvZNRCPoPKdrwmZEbO80Fn7MI/5WpnReBXxN0sJkObwnskyQDASSViXqxgsRy2GWAg61fXtFO4cS9eJdiIUzDwEz3OMedUlHjfJp9/rUWmxtCqwInGn74XJuLULWuCdJ2XLN8sB3iDdQgLOAfTwOVxJXQUXatit1vCAxtbF1S/4cTUxpnD/C57axffYY+dHIhM14pARWryGEt24r0y0vtn1my66NezIYSJKalAa5KVXG+Lqu3cL2RXM7l9RH0uW2N5Z0PvBBYqPj5b2OgUr6zmifdw/b9LpsTSYCkVfN9S8nfVMC3O7S0J9bdGdCkGWCJKmJ7T/2cfkhzL4Cd6RzEwZF08FuwOq2D5S0CvAc25e35FJno+NnmbXR8XMVrp/e9XFf2/RKd/sjkpZybC5sHUkvIJrs1mXojXPM1RmbopRivkE0s95NqI7eTPSNJKOQwUCSjCGSNiNGAZcb1pQ2hdDyn8gcSsgib03U6B8ETiBEiMYUSZOIWfN/E2I6lW9wto/usjet+7gmjwHXSfod8HDXv9NzhqFhjiICnG8SK5X3ZGRRrYnEF4klYmeVEtEriemNZC5kY0Uy3yNpsmJzXD82nt+QOwsRT6gLAEt2vR4gJhUmMps4tkA+BlBuxAu14UgR9ulFS6Bnkw3YOJXITJxPZB06r7ZYtPQpyPafymhqK/0UDfKk7X8BkyRNsn0OFfctDCqZGUjme0qKdkNJcv0mmV8BG/arqFeas86T9GPbf6prp0nKlMUbgNXoek+w/eWKpp4stfHOnoTlKAuUWuJ3kj4K/IKhT+KV1RmboIHMQtM8VjIot0nah9CIWL5ln/rlfklLEAHXzyTdDTzVsk8TgmwgTAYCSd8AXkCIDnXfGHoa5ZN0NTEG+B4irTqEOjPn4wVJpxJP89Pp0hew/bWKdnYjxIumAkcTmY7P2j6+OW8r+fOHEU73vEdC0oPMyggsBjzS+VSxM6WiP+OqRq+QtL6J0O//IjFhc5DtS9vwpwkU2z8fI35GuxFf089KtiAZhcwMJIPCMsC/GJoGNdDrXP8uxNNzJ70/P7Fqr2qDo2H7Z5KmEyJIAt7Qp7BSv/70Vdpxs9v0YJzV6D1rTfVDxZcJT9eI7RTg5JbdmVBkZiBJKiBpe9u/7eP6r9n+hKS3tPXEPBzFGtuDbd/Yp51NgRs60rqSlgTWtX1ZA27W8WcxYo/AKrbfV57M17Z9Skv+TLe9oaTrbL+4nLvA9svH2I9v2Z42J/GhiSw6JOn9RPPqo0SJqpPFmbATEmNFBgPJQCBpJWJ0bwviDfBC4EO2/1rRzlLE011n7et5wIG9jospFgJNJdb7josxwuLTWsDthBpi5w20kn+llDK105dR6tFXtvV1FoXH6cAettdTLCi6pMrehob9uQh4OdF/8nuiRv9V22uPsR8b2p4+J/GhCS46dBuw2UQXzGqDLBMkg8JRwLHAW8rx7uXcthXt/Ai4HnhrOX5HsfOmOV4xlNOBe4HFFVsKRQQnterQDfGGhuwMadAsss1tvsesYfttknYt/jyqYQsYxphpRO/BfkSNfmvgnWPthO3OBMOVFHltmCmMtPBY+9MwdzCrtyOpQGYGkoFAI2zyG+ncGNr5P9uvr3LNvETSesCW5fAC2zfUsPFr4FzgsHLqg8ArbTcVbFT152Kif+Ei21MlrUFsCNy4DX/GG4ptla+y/VA5XoKQtt68Xc/qI2kDIji/jKE7P9rScpgwpM5AMijcK2n3ojkwWdLuRENhVR5VrEcFQkKYqE9WwvbrJa0gaYfyWq6GL41Qxsp+Sai1rQL8UtIHa5j6L0JQ6W/AX4FNGLpNcaw5gMjErCzpZ8DZwMfbckbSWpKOlHSmpN93Xm35AyzSCQQAyseLtehPExxOlGAuZXxoOUwYMjOQDARFGve7wGZEWv5iomeg0qy/pPWBnxAjSwD/Bt5ZdT+BpLcQu9bPJUoELwc+ZvtXVew0gaRrgc2HPSFebPslY+1L00h6NqFIJ+DSNmvJkq4Bvs/sI5yt3KxKD8O+LkutJG0IfNf2Zm340wSSLp7ImY02yZ6BZL6m071PqOP13SVt+xpg/TK6hO0Hapr6LLCR7buLn8sR2wLHPBggbpRPdh0/SY2Rt/I1vJfZxYt63sTYJJJOIlY9n9QZOWuZp2wfNve/NmZMA46X9PdyvCKhEzGROUfS+4ixwu4yQStCUxOJzAwk8zXjsXsfwq/OeFk5ngRc030vHq97AAAXB0lEQVRuDH35OKHffkI59Uaitv71inYuBi5g9iffE+Z40TykdMu/DXgdcDmhRHiK7cda8ucAYnnOiYyTG5VirfPaRPB3s+0n53LJuKZfoalBJoOBZL6m7CR4H7A40WU8Hrr3O369hHhyhbhpXVuyGG34sxFRqhBwfpcgTRUblRspx4LSJb81kbV4TYs/83F1oyqBwAeYNSZ7LnD4RA8IknpkMJAMBOOtex9A0puIDv7ODfjEMf73F7f9cKfkMZyqJRBJXyJ6DU5rxMEGKNoCOzJLJvkU2/u269X4oIhNLUhIR0OMyT5t+z3teZW0RQYDSVIRSZsze138J605VBNJv7W9vaS/MFSJrpM1WaWivQeJDMwT5dV29uUXxETD6cS0xLmdmfox9mNr278vwd9suMf9GE0j6Rrb68/tXDIYZANhklRA0jHAGsAMZtXFTUwYTChsb1/+XLkhe+NtZ8NRwNttz+xfkLRgC2nw/0eMu+04wueq7MdomqclrWH7DgBJq9PV65EMFpkZSJIKSLqJ0Nufb/7jSDrT9nZzO9eDnc6muOfb/qKklYEVbV/eoLuVKX69Eng7sKPtFdr0Z7wgaRsiYLqTyOKsCuxp+5xWHesDSScQKqG/bSMLNJHJYCBJKiDpeGA/23f1aWcH4LQ237AkLUSs0r2AWb0LAFOAs2yvU9HeYcRymK1tv1DS0oSi3UYNul3Fn02IAOCNxNbKvYkxw3+PsR/7j/Z5t7j+WtLCDJ0meHwul4xrJL2K2MC4KbGu/Me2b27Xq4lBlgmSgaAoBR5APP0sQMVtZl0b3pYEbpR0OUPHw6pqGOwCfLs8yRzldlb97k1s9VseuIFZwcADhDhOVTYpsr9XA9j+dwk4xhRJ/0PsjvgzMa1xILEw6ehRL5x3jKvySZkc+Yvtf9h+XNJLgZ2BP0k6YCLP5Ns+CzhLsVBsV+B3pSfmSOCnOSkxZzIzkAwEkm4GPszsM/A9SRLPacNbl53Km95KF/+uxJOMiZTtcS4rgMcKSdNsf6sBO5cRcsRXlKBgOSIzsEHfTlbz4x7gFuBbFF0BSXfmrHkg6SpiJ8F9kl4B/BzYF3gp8ELbb27VwT4pqpO7E9MRfwd+RmS+Xmx7qxZdG9dkMJAMBJIus71JA3Y6ioajnqtgb1nijWsacBOwJvAd24f062tFP9YB1iXKBgDYPraijd2YNcJ3NPBm4LO2j2/Q1V78mAxsRwRaWwPnAK8CVrb91Fj6Msyv1YFvEylsA5cAH7Z95xj7MXNiQNL3gHtsH1COx6VWRK8olmWtAxxDlAju6vrclbZf1ppz45wMBpKBQNJXgclE53Z3ev+qinauGq5kKOnaqjr+knYE9iImE44BjrZ9t6TFgJtsr1rFXj9I+ixx81wHOAN4NXCh7V7XMnfbWofYFCjg7JbKH93+LALsQAQGWxaf3t6SL5cC32OW0NQuxG6AvoPUin5cD7zU9lMlY/Y+2+d3Pmd7vbH0p0k6Y5xt+zERyWAgGQgkjdQhbdtb93j9B4iVvKsTO9M7LEkI7exW0Z+fAD/ovAkP+9w2ts+uYq8fimTzS4GrbK8vaUVCia6nPghJy4z2+fFSgy5lmTe21TswUnZK0qW2Nx1jPz4DvBa4l9hSOdW2Ja1JBKVbjKU/TTAnDYcObWk5TCQyGEiSHigNSUsDXwE+2fWpB8fLza4uki63vbGk6cBWwEPAdb0+IRaZ3Y7E8yrEJkcBzwL+bPv588TxCUbJTt1P1OhNlFQWJrIFYxo0SdqUWEx0pssSJ0lrAUtUzZaNByQdVT5cnuhb6WQHXkmITVXOcg0aGQwkA0G5mX+eWTrs5wEH2v5PDVuTgRUYqkD454o2NgUOAV4ILESUMB5uQ61P0uHAJwiNgP2IaYKbbO9R0c73idG908rx9kSj2kcadnlCMofdBB16nmxJ5oykU4D3dnoFSpbrexkMzJ0MBpKBoIzwXc9QHfb1q75JSNqHGFH8JzFTD/FGXrVn4EqiZnw88DJgD2BN25+pYqdpSqp4Sp2nQ0nTbW847Fw2bSVjxvCeB8U20Gsnch/EWJE6A8mgsIbtnbuOvyBpRg0704C1ex1JHA3bt0uaXORyj1KsAB5zutUGbd8+/FwF7i3NiD8l0uC7A31/n6oy3urH43U3wXzKuZLOIJo0TQTcE1ZRcSzJYCAZFB6VtKXtC2GmCNGjNez8BahcWhiBR4ogzwxJBwF3EUt+xowuBcIVJC3JUAXCSkuKCrsSpZjO9sXzy7mxprMDYMT6MWO/C2C87iaY77C9j6Q3MqsceITHeBvoRCXLBMlAUFTWjgaWIm569wHvsn1NRTs/JORbT2XoiGIlSVlJqxKlhoUIMaSlgEM7T+ZjgaQPM0uB8J8MVSA8sgkhojbJ+vFgImkFYGMi0Lrc9t0tuzQhyGAgGSjKeBm2H6h5/edHOm/7CzVsLVeuvaeOL01QmiE/Zvurfdj4lu1pXZLNQ6gh1dwI461+LOnLwEG27y/HSwMfsf3ZNvyZH5H0VuB/iQyQgJcTv9+/atOviUAGA8lAIOlDhNzvg4RO+VTgk7bPrGlvSaJx8KGK14lIpe9DvFlNAp4CDrF9YB1f+qXfWXdJG9qePifJ5jpSzU0g6bvACxhaP77d9r4t+XP1cGnmkUSskvpIugbYtpMNKAH3WR3FxWTOTGrbgSQZI/Yq2YDtiLT4nkDlp2FJ6ykW8VwP3CBpuqQXVTAxDdgC2Mj2s20vDWwCbFHS9m3wO0mvr3ux7enlz/M6L+Ba4N9tBQLFn32Aw4H1CVGlI9oKBAqTFVsCAZC0KKEzkDTHpGFlgX+R97meyAbCZFDo1MNfS2wJvKY8pVflCGB/l53vkrYiMg2b93j9HsSTy72dE7bvlLQ7cCbwzRo+9cs+wFKSHieaKjsbHUdVFhyOpHOBnYj3lRnAPZLOsz3qCt95SenUHy8Nej8Fzi4COSbkqNvapDi/cnrXNAGEsNNpLfozYcgyQTIQlDfg5wHPJ54UJxPKZBuOeuHsdq4ZnnIc6dwo189R+70tXfjSNzAbZeSxip2rbW8g6T3EUqDP19nb0BTjSdipy6fXEEuTRKj/ndGWL/MrZYRzS+J7fH5OE/RGZgaSQeHdRKr4TtuPKNac7lnDzp2SPkcsF4KYpR9NWW44T9T83DzD9tOSXsuscaxzbZ9ew9QCpWP/rUCr4kmF7zKCsFNbzkhanAgATpe0NrC2pAVtP9mWT/MjnWyQYiPomOtcTFSylpIMBLafIW7aayl2uL+I0M6vyl7AckTq+cTycZWgYn1JD4zwehB4cQ1/+kbS/wAfB+4sr49L+lINUwcSWw/vsH2FYmXvbc15Wp0yqjnZ9tO2jyK0BtrifGARSc8DziJ+b37coj/zDZI2lXSupF9L2kCxmfF64J8lG5PMhSwTJANBSV1/CFiJqGdvClziHrcWzs9IuhbYoFMWkLQAscGwlfR+U0g6n0jJ/wD4ByHs9K62Oss7kwOS9gUWtX3QSBMGSXWKvPenCb2OI4DtbV+qWKl9XH6P506WCZJB4UPARsCltl9Z3iR61gaQdNJon29rlr5BphDbBiHWMldGsfXuMGAF2+tJegmwk+06WYYmeAeR/dyHEHZaGdh51CvmLZK0GbEQ6t3lXL4HN8MCnTFhSQfavhTA9s31+oQHj/xFTAaFx2w/JglJC5c3ibUrXL8ZIUV8HHAZs6YT5gcOAq6SdDbxdW0F/HcNO0cCHyPG+bB9raRjgVaCAdt/KpLLqwAnALe0XJ+fBnwKONH2DaWMkrr5zfBM18fDZcYz/d0DWSZIBgJJJxI12mnA1sRT8IK2X9vj9ZOBbQmt/ZcQcsTH2b5h3ng8tpQ69ibl8DLbf6th4wrbG3WnviXNsP3SJn2t4M9WxOjeH4kgZ2XgnbbPb8OfZN4h6WngYeLnvCjwSOdTwCK2F2zLt4lCZgaSgcD2G8uHB0g6h6gt9twxX+rppxNzzAsTQcG5JSV5SOMOjz0bEn0UBp4EKgcDxNbCNYoNJL2ZqNO3xTeA7WzfUvxZi8jsVBon7ZfxKtc8P2F7xPHYpHcyGEgGBklbAi+wfVSRKX0eFcYCSxDwOiIQWA34DuNH0KY2kg4B1gV+Xk7tJ2m7Gmp9exPNW+tI+hvxvd29OU8rs2AnEACwfaukNp4QO2OoX2/h306SnsgyQTIQlAVDLwPWtr2WpOcCx9veosfrjwbWA34L/Nz29fPO27FF0g3Aei5vBqUkcq3tKjLL3fYWJ2RhH2zQzTp+/Ih4Eu/cjHcjGs3q6Es05VPry6mSZCRSZyAZFN5ISOU+DGD771Trmn8HsBYxlXBxtz6ApFobEMcRtxIjlx1WJGa0e0bS5CLygu2HgcclvVfSTc25WZkPADcA+xE/txuB/xprJxQcIOle4GbgVkn3SKrTpJkk84QsEySDwhO2Lanz9Lt4lYttz8+B81LATZIuLcebEAHPrwFsv2m0iyXtQkwQPCzpNuAA4mn8CuJpvBVsPw4cXF5t0r2c6g8AZZLgMEkftt3GPookGUKWCZKBQNJHiXW22wJfIZQEj7P9nVYdGwdI2ma0z9s+ey7XXw+8wfbtkqYClwC7tKUJL+k6RhknG2sxJcWWyyHLqcr55Qh54hTESVong4FkYJC0LbHCWMAZtn/XskvjAsUq3cdK5mQNYG3iJvVUj9dfZXtq1/HNtteZR+724s+qo33e9p/GyhcYn8upkmQ4WSZIBoZy8/8dzKxx72b7Zy27NR64AHiFpKWA84CriQU/e/R4/fKSutcUL9F9bHtM0/RjfbPvgXG3nCpJhpPBQDJfI2kKMfL2POAkIhjYm1DKmwFkMBCd/49I2gv4ru2vSppR4fojGdqMOfx40Fl/Dk2mAhYZa2eSZCQyGEjmd44h1AYvAd5DBAELAa+3XeWGNz8zSdJGwNuB95VzPYu42O55x8MgkoI4yUQgg4Fkfmd12y8GkPQD4F5glbZn4McZ+xNLm061fX3pdL+gZZ/6RtKGtqcPO7ej7ZPb8ilJxivZQJjM14zQ3DbkOJl/kXQVsYvgunK8KzDN9iajX5kkg0cGA8l8TdcCExi6xESAbU9py7fxgqQ1iezAanRlC21v15ZPTVAyHL8itA62JBoid7D9n1YdS5JxSAYDSTLglGbBHwLTgac7521fVtHOs4gb7moMDSr2a8TRGpTlRL8h1k+/wfbw9bZJkpA9A0mSwDMNbV48DbgUuI6h++XHlBFEh5YhGiIvkzTmokNJMhHIzECSDDhlidNdwInA453ztivtXBgv/RjjTXQoSSYCGQwkyYAj6S8jnLbtVSra+TDwEHAKQ4OK+/rzsDqSJhGbF1PdL0l6IMsESTLg2F65IVNPAP8LfIZZaXoDqzdkv2dsPyPpGkmr2P7zWP/7STLRyMxAkiRIWgdYly5FPNvHVrRxB7DJ8IU8bSHp98BGwOXMmijB9k6tOZUk45TMDCTJgCPps8QCp3WAM4BXAxcClYIB4AZibHO8kMqISdIjGQwkSfI24KXAVbbfIWlF4PAadp4GZkg6h6E9A62MFto+T9IKRHYA4HLbd7fhS5KMdzIYSJLkUdtPS3pK0pLAP6hX5/9NeY0LJL2V6GE4lxCZOkTSx2z/qlXHkmQcksFAkiRXF8GgHwFXAg8AV1U1YvtoSQsBa5VTt9h+sjk3K/MZYKNONkDScsBZhCphkiRdZANhkgwwkgQ8x/Zd5XhNYIrtysGApK2Ao4E/Ek/iKxO7Ac5vzOFq/lzXWVJVjicB13SfS5IkyMxAkgwwti3pFGDDcnx7H+a+AWxn+xaYKQV8XMd2C5wu6YziA0RvxGkt+ZIk45oMBpIkuVzS1DrZgGEs2AkEAGzfKmnBPm3WxvbHJO0MbEFkKo6wfWJb/iTJeCbLBEkyoEhawPZTRcv/hcAdxDx+Z6NjJWlhST8iRIaOKad2AxawvWeDbvfixzTgIuBq20+N5b+dJBOVDAaSZEDp7BKQtMZIn7d9R0V7CwN7E+uCBZwPHGr78VEvbBhJXwc2J3QTrgUuJoKDS9qQRk6SiUAGA0kyoEi62vYGDdmaDBxte/cm7DVBmWx4GREYbFZe99tet1XHkmQckj0DSTK4LCdp/zl90vbBvRoqOgXLSVrI9hPNuNc3iwJTgKXK6+/EeuUkSYaRwUCSDC6TgSWIlH4T/BG4SNJJDN0F0HNQ0QSSjgBeBDwIXEaUCQ62/e+x9CNJJhIZDCTJ4HKX7QMbtPf38poELNmg3aqsAiwM3Ab8DfgrcH+L/iTJuCeDgSQZXBrJCEg6xvY7iHr8t5uw2Q+2X1PElF5E9At8BFhP0n1EE+HnW3UwScYh2UCYJAOKpGWa6K6XdCOwPXASsBXDgow2O/glrUToDGwO7AA82/az2vInScYrGQwkSdIXkvYDPkAsN/obQ4MB266z9KhffzYngoAnKWOF5c/rbD8zlv4kyUQgg4EkSRpB0mG2PzAO/DiYoi3Q2bmQJMnoZDCQJEmSJAPOpLYdSJIkSZKkXTIYSJIkSZIBJ4OBJEkaQ9Kqkl5VPl5UUpt6A0mS9EgGA0mSNIKk9wK/Ag4vp1YCftOeR0mS9EoGA0mSNMXexDjfAwC2bwOWb9WjJEl6IoOBJEma4vHuJUWSFgByXClJJgAZDCRJ0hTnSfo0sKikbYHjgZNb9ilJkh5InYEkSRpB0iTg3cB2hArhGcAPnG8ySTLuyWAgSZJGkLQ48Jjtp8vxZGBh24+061mSJHMjywRJkjTF2cCiXceLAme15EuSJBXIYCBJkqZYxPZDnYPy8WIt+pMkSY9kMJAkSVM8LGlq50DShsCjLfqTJEmPLNC2A0mSzDdMA46X9PdyvCLwthb9SZKkR7KBMEmSxpC0ILA2MU1ws+0nW3YpSZIeyGAgSZLGkLQ5sBpdWUfbP2nNoSRJeiLLBEmSNIKkY4A1gBnA0+W0gQwGkmSck5mBJEkaQdJNwLopMpQkE4+cJkiSpCmuB57TthNJklQnywRJkjTFssCNki4HHu+ctL1Tey4lSdILGQwkSdIUB7TtQJIk9ciegSRJkiQZcLJnIEmSRpC0qaQrJD0k6QlJT0t6oG2/kiSZOxkMJEnSFN8FdgVuI5YUvaecS5JknJM9A0mSNIbt2yVNLmuMj5J0cds+JUkydzIYSJKkKR6RtBAwQ9JBwF3A4i37lCRJD2SZIEmSpngH8Z6yD/AwsDLwplY9SpKkJzIYSJKkKd5g+zHbD9j+gu39gR3adipJkrmTwUCSJE3xzhHOvWusnUiSpDrZM5AkSV9I2hV4O/B8SSd1fWoK8K92vEqSpAoZDCRJ0i8XE82CywLf6Dr/IHBtKx4lSVKJVCBMkqQRJC0OPGr7GUlrAesAv7X9ZMuuJUkyFzIYSJKkESRNB14OLA1cClwJPGJ7t1YdS5JkrmQDYZIkTSHbjxDjhIfYfiOwbss+JUnSAxkMJEnSFJK0GbAbcGo5l31JSTIByGAgSZKmmAZ8CjjR9g2SVgfOadmnJEl6IHsGkiRJkmTAyRRekiR9IelbtqdJOhmY7enC9k4tuJUkSQUyGEiSpF+OKX9+vVUvkiSpTZYJkiRpDEnLAdi+p21fkiTpnWwgTJKkLxQcIOle4GbgVkn3SPrvtn1LkqQ3MhhIkqRfpgFbABvZfrbtpYFNgC0kfbhd15Ik6YUsEyRJ0heSrga2tX3vsPPLAWfa3qAdz5Ik6ZXMDCRJ0i8LDg8EYGbfwIIt+JMkSUUyGEiSpF+eqPm5JEnGCVkmSJKkLyQ9DTw80qeARWxndiBJxjkZDCRJkiTJgJNlgiRJkiQZcDIYSJIkSZIBJ4OBJEmSJBlwMhhIkiRJkgEng4EkSZIkGXD+P8Iwdzmwv0ZIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "AbsentsY = AbsentsX['Absent']\n",
    "AbsentsX = AbsentsX.drop(columns=\"Absent\")\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "Columns = [x for x in AbsentsX]\n",
    "\n",
    "def feature_selectionKBest(nr_features):\n",
    "    \n",
    "    global AbsentsX,AbsentsY,X_test\n",
    "    feature_selector = SelectKBest(chi2,k=nr_features).fit(AbsentsX,AbsentsY)\n",
    "    \n",
    "    \n",
    "    keep_feature = feature_selector.get_support()\n",
    "    \n",
    "    droping_columns = [Columns[x] for x in range(len(keep_feature))\n",
    "                          if keep_feature[x] == 0]\n",
    "    \n",
    "    AbsentsX = AbsentsX.drop(columns=droping_columns)\n",
    "    X_test  = X_test.drop(columns=droping_columns)\n",
    "    \n",
    "    \n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "def feature_selectionRFE(nr_features):\n",
    "    \n",
    "    global AbsentsX,AbsentsY,X_test\n",
    "    estimator = SVR(kernel=\"linear\")\n",
    "    selector = RFE(estimator, nr_features, step=1)\n",
    "    selector = selector.fit(AbsentsX,AbsentsY)\n",
    "        \n",
    "    keep_feature = selector.get_support()\n",
    "    \n",
    "    droping_columns = [Columns[x] for x in range(len(keep_feature))\n",
    "                          if keep_feature[x] == 0]\n",
    "    \n",
    "    AbsentsX = AbsentsX.drop(columns=droping_columns)\n",
    "    X_test  = X_test.drop(columns=droping_columns)\n",
    "    \n",
    "\n",
    "\n",
    "def featureExtraction(correlation_coefficient):\n",
    "    global AbsentsX,AbsentsY,X_test,Columns\n",
    "    correlation = AbsentsX.corr()\n",
    "    \n",
    "    new_columns = list()\n",
    "    \n",
    "    \n",
    "    while(len(Columns) > 0):\n",
    "        copy_columns = list(Columns)\n",
    "        new_column = list()\n",
    "        column = Columns[0]\n",
    "        Columns.remove(column)\n",
    "        new_column.append(column)\n",
    "        for i in copy_columns:\n",
    "            if(i != column):\n",
    "                if AbsentsX[column].corr(AbsentsX[i]) > correlation_coefficient:\n",
    "                    new_column.append(i)\n",
    "                    Columns.remove(i)\n",
    "        new_columns.append(new_column)\n",
    "              \n",
    "    \n",
    "    for x in new_columns:\n",
    "        averages = list()\n",
    "        for index,row in AbsentsX.iterrows():\n",
    "                average = 0;\n",
    "                for i in x:\n",
    "                    average += row[i]\n",
    "                average = average/len(x)\n",
    "                averages.append(average)\n",
    "                            \n",
    "        AbsentsX = AbsentsX.drop(columns = x)\n",
    "        AbsentsX.insert(len(AbsentsX.columns),\" + \".join(x),averages)    \n",
    "    \n",
    "                \n",
    "    \n",
    "    for x in new_columns:\n",
    "        averages = list()\n",
    "        for index,row in X_test.iterrows():\n",
    "                average = 0;\n",
    "                for i in x:\n",
    "                    average += row[i]\n",
    "                average = average/len(x)\n",
    "                averages.append(average)\n",
    "                            \n",
    "        X_test = X_test.drop(columns = x)\n",
    "        X_test.insert(len(X_test.columns),\" + \".join(x),averages)    \n",
    "\n",
    "        \n",
    "feature_selectionKBest(15)\n",
    "\n",
    "##feature_selectionRFE(15)\n",
    "\n",
    "##featureExtraction(0.5)\n",
    "\n",
    "sns.heatmap(AbsentsX.corr())      \n",
    "AbsentsX.insert(len(AbsentsX.columns),\"Absent\",AbsentsY)\n",
    "AbsentsX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = AbsentsX.drop(columns= 'Absent')\n",
    "Y = AbsentsX['Absent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression\n",
    "### Area under the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##X_test = X_new.transform(X_test)\n",
    "\n",
    "##X = Absents.drop('Absent',axis = 1)\n",
    "##Y = Absents['Absent']\n",
    "\n",
    "lm = LinearRegression(fit_intercept=False,normalize=True,copy_X= False)\n",
    "lm.fit(X,Y)\n",
    "predictions = lm.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "predictions = [int( x  > 0.5) for x in predictions]\n",
    "print(predictions)\n",
    "accuracy_score(Y_test['Absent'],predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'copy_X': False, 'fit_intercept': True, 'n_jobs': None, 'normalize': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugoa\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'fit_intercept': [True,False], 'normalize': [True,False], 'copy_X': [False,True],'n_jobs': [None,1,2,4,8,16,32]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(LinearRegression(),param_grid,refit=True,verbose=0,cv=5)\n",
    "grid.fit(X,Y)\n",
    "print(grid.best_params_)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "grid_predictions = [int( x  > 0.5) for x in grid_predictions]\n",
    "accuracy_score(Y_test['Absent'],grid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier(strategy= 'most_frequent')\n",
    "clf.fit(X,Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'strategy': 'stratified'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugoa\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\hugoa\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5541666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'strategy': ['stratified','most_frequent',\n",
    "                          'prior','uniform']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(DummyClassifier(),param_grid,refit=True,verbose=0)\n",
    "grid.fit(X,Y)\n",
    "print(grid.best_params_)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],grid_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.275"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(solver = 'saga')\n",
    "LR.fit(X,Y)\n",
    "predictions = LR.predict(X_test)\n",
    "print(predictions)\n",
    "accuracy_score(Y_test['Absent'],predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18333333333333332"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "predictions = kmeans.predict(X_test)\n",
    "print(predictions)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 0\n",
      " 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X,Y)\n",
    "predictions = knn.predict(X_test)\n",
    "print(predictions)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(gamma = 'auto')\n",
    "model.fit(X,Y)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.700, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.700, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.638, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.667, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.667, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.638, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.633, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugoa\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.667, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.655, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.717, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.683, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.638, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.667, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.650, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.638, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.600, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.600, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.638, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.700, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.667, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.621, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.750, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.683, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.707, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.667, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.650, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.638, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.517, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.600, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.600, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.672, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.650, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.683, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.569, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.717, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.767, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.655, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.717, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.700, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.707, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.667, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.650, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.638, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.3s finished\n",
      "C:\\Users\\hugoa\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "grid.fit(X,Y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20416666666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],grid_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-895160768884>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    611\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[0;32m    612\u001b[0m                                        dtype=np.float64)\n\u001b[1;32m--> 613\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    718\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X,Y)\n",
    "predictions = classifier.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19166666666666668"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X, Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer percetron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X,Y)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2916666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X,Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3375"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 200)\n",
    "\n",
    "##params_rf = {'n_estimators': [50, 100, 200,400]}\n",
    "\n",
    "##rf_gs = GridSearchCV(rf, params_rf, cv=5)\n",
    "\n",
    "##rf_gs.fit(X, Y)\n",
    "\n",
    "rf.fit(X,Y)\n",
    "\n",
    "##print(rf_gs.best_params_)\n",
    "predictions = rf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PassiveAgressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21666666666666667"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=0,\n",
    "tol=1e-3)\n",
    "clf.fit(X, Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7416666666666667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "clf = NearestCentroid()\n",
    "clf.fit(X, Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RadiusNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No neighbors found for test samples [7, 13, 49, 51, 63, 69, 76, 183, 204], you can try using larger radius, give a label for outliers, or consider removing them from your dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-51bc348b5d0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRadiusNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m                              \u001b[1;34m'give a label for outliers, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m                              \u001b[1;34m'or consider removing them from your dataset.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m                              % outliers)\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No neighbors found for test samples [7, 13, 49, 51, 63, 69, 76, 183, 204], you can try using larger radius, give a label for outliers, or consider removing them from your dataset."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "clf = RadiusNeighborsClassifier(radius=1.9)\n",
    "clf.fit(X,Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6291666666666667"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "                            \n",
    "clf = BaggingClassifier(base_estimator=SVC(gamma='auto'),\n",
    "                       n_estimators=10, random_state=0)\n",
    "clf.fit(X, Y)\n",
    "predictions = clf.predict(X_test)\n",
    "print(predictions)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "### needs sklearn version 0.23 or  above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StackingClassifier' from 'sklearn.ensemble' (C:\\Users\\hugoa\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-85306df21c21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'StackingClassifier' from 'sklearn.ensemble' (C:\\Users\\hugoa\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39 0.1  0.01 0.02 0.04 0.01 0.01 0.15 0.15 0.01 0.02 0.   0.03 0.05\n",
      " 0.01]\n",
      "5 : predicted0 actual 1\n",
      "7 : predicted0 actual 1\n",
      "8 : predicted0 actual 1\n",
      "9 : predicted0 actual 1\n",
      "10 : predicted0 actual 1\n",
      "11 : predicted0 actual 1\n",
      "12 : predicted0 actual 1\n",
      "13 : predicted0 actual 1\n",
      "14 : predicted0 actual 1\n",
      "15 : predicted0 actual 1\n",
      "16 : predicted0 actual 1\n",
      "18 : predicted0 actual 1\n",
      "19 : predicted0 actual 1\n",
      "20 : predicted0 actual 1\n",
      "21 : predicted0 actual 1\n",
      "22 : predicted0 actual 1\n",
      "24 : predicted0 actual 1\n",
      "26 : predicted0 actual 1\n",
      "32 : predicted0 actual 1\n",
      "33 : predicted0 actual 1\n",
      "34 : predicted0 actual 1\n",
      "35 : predicted0 actual 1\n",
      "36 : predicted0 actual 1\n",
      "37 : predicted0 actual 1\n",
      "39 : predicted0 actual 1\n",
      "41 : predicted0 actual 1\n",
      "42 : predicted0 actual 1\n",
      "43 : predicted0 actual 1\n",
      "44 : predicted0 actual 1\n",
      "45 : predicted0 actual 1\n",
      "46 : predicted0 actual 1\n",
      "47 : predicted0 actual 1\n",
      "48 : predicted0 actual 1\n",
      "49 : predicted0 actual 1\n",
      "50 : predicted0 actual 1\n",
      "51 : predicted0 actual 1\n",
      "52 : predicted0 actual 1\n",
      "53 : predicted0 actual 1\n",
      "55 : predicted0 actual 1\n",
      "56 : predicted0 actual 1\n",
      "57 : predicted0 actual 1\n",
      "58 : predicted0 actual 1\n",
      "59 : predicted0 actual 1\n",
      "60 : predicted0 actual 1\n",
      "61 : predicted0 actual 1\n",
      "62 : predicted0 actual 1\n",
      "63 : predicted0 actual 1\n",
      "69 : predicted0 actual 1\n",
      "75 : predicted1 actual 0\n",
      "91 : predicted1 actual 0\n",
      "101 : predicted1 actual 0\n",
      "102 : predicted1 actual 0\n",
      "103 : predicted1 actual 0\n",
      "104 : predicted1 actual 0\n",
      "105 : predicted1 actual 0\n",
      "112 : predicted1 actual 0\n",
      "128 : predicted1 actual 0\n",
      "138 : predicted1 actual 0\n",
      "139 : predicted1 actual 0\n",
      "140 : predicted1 actual 0\n",
      "141 : predicted1 actual 0\n",
      "142 : predicted1 actual 0\n",
      "149 : predicted1 actual 0\n",
      "159 : predicted0 actual 1\n",
      "162 : predicted0 actual 1\n",
      "165 : predicted1 actual 0\n",
      "166 : predicted0 actual 1\n",
      "169 : predicted0 actual 1\n",
      "172 : predicted0 actual 1\n",
      "173 : predicted0 actual 1\n",
      "175 : predicted1 actual 0\n",
      "176 : predicted1 actual 0\n",
      "178 : predicted1 actual 0\n",
      "179 : predicted1 actual 0\n",
      "184 : predicted0 actual 1\n",
      "186 : predicted1 actual 0\n",
      "187 : predicted0 actual 1\n",
      "188 : predicted0 actual 1\n",
      "190 : predicted0 actual 1\n",
      "200 : predicted0 actual 1\n",
      "202 : predicted1 actual 0\n",
      "207 : predicted0 actual 1\n",
      "208 : predicted0 actual 1\n",
      "209 : predicted0 actual 1\n",
      "211 : predicted0 actual 1\n",
      "212 : predicted1 actual 0\n",
      "217 : predicted0 actual 1\n",
      "223 : predicted1 actual 0\n",
      "239 : predicted1 actual 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6291666666666667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators = 100, random_state=0)\n",
    "clf.fit(X, Y)\n",
    "print(clf.feature_importances_)\n",
    "preditions = clf.predict(X_test)\n",
    "for x in range(len(predictions)):\n",
    "    if(predictions[x] != Y_test['Absent'][x]):\n",
    "        print(str(x) + \" : predicted\" + str(predictions[x]) + \" actual \" + str(Y_test['Absent'][x]) ) \n",
    "        \n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(multi_class='multinomial',solver = 'saga', random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6291666666666667"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf1 = VotingClassifier(estimators=[\n",
    "         ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "eclf1 = eclf1.fit(X.values, Y.values)\n",
    "preditions = eclf1.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6291666666666667"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf2 = VotingClassifier(estimators=[\n",
    "   ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "  voting='soft')\n",
    "eclf2 = eclf2.fit(X, Y)\n",
    "\n",
    "preditions = eclf2.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18333333333333332"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf3 = VotingClassifier(estimators=[\n",
    " ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    " voting='soft', weights=[2,1,1],\n",
    " flatten_transform=True)\n",
    "eclf3 = eclf3.fit(X, Y)\n",
    "predictions = eclf3.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X,Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parametrization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(gamma = 'auto')\n",
    "model.fit(X,Y)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "grid.fit(X,Y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "print(accuracy_score(Y_test['Absent'],grid_predictions))\n",
    "plt.scatter(Y_test['Absent'],grid_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Radius Neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "\n",
    "clf = RadiusNeighborsClassifier(radius=1.9)\n",
    "clf.fit(X,Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'algorithm':['auto','ball_tree', 'kd_tree', 'brute'],'radius':[1.9,2.5,3,4,5,10],\n",
    "             'leaf_size':[15,30,45,50]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(RadiusNeighborsClassifier(),param_grid,cv=5,refit=True,verbose=0)\n",
    "grid.fit(X,Y)\n",
    "print(grid.best_params_)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],grid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(Y_test['Absent'],grid_predictions))\n",
    "plt.scatter(Y_test['Absent'],grid_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators = 100, random_state=0)\n",
    "clf.fit(X, Y)\n",
    "print(clf.feature_importances_)\n",
    "preditions = clf.predict(X_test) \n",
    "        \n",
    "print(accuracy_score(Y_test['Absent'],predictions))\n",
    "plt.scatter(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [1, 10, 100, 1000], 'learning_rate': [1,0.1,0.01], 'algorithm': ['SAMME']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(AdaBoostClassifier(),param_grid,refit=True,verbose=3,cv=5)\n",
    "grid.fit(X,Y)\n",
    "print(grid.best_params_)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
