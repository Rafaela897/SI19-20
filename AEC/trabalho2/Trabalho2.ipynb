{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15454efb6c8>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Absents = pd.read_csv(\"train_data.csv\")\n",
    "X_test  = pd.read_csv(\"test_data.csv\")\n",
    "Y_test  = pd.read_csv(\"sample_submission.csv\")\n",
    "sns.distplot(Absents['Absent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre tratemento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239554</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>261756</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>170</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>261756</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>170</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>261756</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>172</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>261756</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>196</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>291</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>261756</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>171</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reason for absence  Month of absence  Day of the week  Seasons  \\\n",
       "0                    26                 7                3        1   \n",
       "1                     0                 7                3        1   \n",
       "2                    23                 7                4        1   \n",
       "3                     7                 7                5        1   \n",
       "4                    23                 7                5        1   \n",
       "..                  ...               ...              ...      ...   \n",
       "495                  28                 9                3        1   \n",
       "496                  28                 9                3        1   \n",
       "497                  28                 9                3        1   \n",
       "498                  23                 9                3        1   \n",
       "499                  28                 9                5        1   \n",
       "\n",
       "     Transportation expense  Distance from Residence to Work  Service time  \\\n",
       "0                       289                               36            13   \n",
       "1                       118                               13            18   \n",
       "2                       179                               51            18   \n",
       "3                       279                                5            14   \n",
       "4                       289                               36            13   \n",
       "..                      ...                              ...           ...   \n",
       "495                     246                               25            16   \n",
       "496                     246                               25            16   \n",
       "497                     118                               10            10   \n",
       "498                     155                               12            14   \n",
       "499                     291                               31            12   \n",
       "\n",
       "     Age  Work load Average/day   Hit target  Disciplinary failure  Education  \\\n",
       "0     33                  239554          97                     0          1   \n",
       "1     50                  239554          97                     1          1   \n",
       "2     38                  239554          97                     0          1   \n",
       "3     39                  239554          97                     0          1   \n",
       "4     33                  239554          97                     0          1   \n",
       "..   ...                     ...         ...                   ...        ...   \n",
       "495   41                  261756          87                     0          1   \n",
       "496   41                  261756          87                     0          1   \n",
       "497   37                  261756          87                     0          1   \n",
       "498   34                  261756          87                     0          1   \n",
       "499   40                  261756          87                     0          1   \n",
       "\n",
       "     Son  Social drinker  Social smoker  Pet  Weight  Height  Body mass index  \n",
       "0      2               1              0    1      90     172               30  \n",
       "1      1               1              0    0      98     178               31  \n",
       "2      0               1              0    0      89     170               31  \n",
       "3      2               1              1    0      68     168               24  \n",
       "4      2               1              0    1      90     172               30  \n",
       "..   ...             ...            ...  ...     ...     ...              ...  \n",
       "495    0               1              0    0      67     170               23  \n",
       "496    0               1              0    0      67     170               23  \n",
       "497    0               0              0    0      83     172               28  \n",
       "498    2               1              0    0      95     196               25  \n",
       "499    1               1              0    1      73     171               25  \n",
       "\n",
       "[500 rows x 19 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs = [x for x in Absents['Absent'] if x == 1]\n",
    "workload = [int(x.replace(\",\",\"\")) for x in Absents['Work load Average/day ']]\n",
    "Absents['Work load Average/day '] = workload\n",
    "\n",
    "Absents = Absents.drop(columns = 'ID')\n",
    "X_test  = X_test.drop(columns  = 'ID')\n",
    "\n",
    "AbsentsY = Absents['Absent'] \n",
    "AbsentsX = Absents.drop(columns = 'Absent')\n",
    "AbsentsX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.194471</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.194471</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.194471</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.194471</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.194471</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474074</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474074</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137037</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640741</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reason for absence  Month of absence  Day of the week  Seasons  \\\n",
       "0              0.928571          0.545455             0.25      0.0   \n",
       "1              0.000000          0.545455             0.25      0.0   \n",
       "2              0.821429          0.545455             0.50      0.0   \n",
       "3              0.250000          0.545455             0.75      0.0   \n",
       "4              0.821429          0.545455             0.75      0.0   \n",
       "..                  ...               ...              ...      ...   \n",
       "495            1.000000          0.727273             0.25      0.0   \n",
       "496            1.000000          0.727273             0.25      0.0   \n",
       "497            1.000000          0.727273             0.25      0.0   \n",
       "498            0.821429          0.727273             0.25      0.0   \n",
       "499            1.000000          0.727273             0.75      0.0   \n",
       "\n",
       "     Transportation expense  Distance from Residence to Work  Service time  \\\n",
       "0                  0.633333                         0.659574      0.384615   \n",
       "1                  0.000000                         0.170213      0.576923   \n",
       "2                  0.225926                         0.978723      0.576923   \n",
       "3                  0.596296                         0.000000      0.423077   \n",
       "4                  0.633333                         0.659574      0.384615   \n",
       "..                      ...                              ...           ...   \n",
       "495                0.474074                         0.425532      0.500000   \n",
       "496                0.474074                         0.425532      0.500000   \n",
       "497                0.000000                         0.106383      0.269231   \n",
       "498                0.137037                         0.148936      0.423077   \n",
       "499                0.640741                         0.553191      0.346154   \n",
       "\n",
       "          Age  Work load Average/day   Hit target  Disciplinary failure  \\\n",
       "0    0.193548                0.194471    0.842105                   0.0   \n",
       "1    0.741935                0.194471    0.842105                   1.0   \n",
       "2    0.354839                0.194471    0.842105                   0.0   \n",
       "3    0.387097                0.194471    0.842105                   0.0   \n",
       "4    0.193548                0.194471    0.842105                   0.0   \n",
       "..        ...                     ...         ...                   ...   \n",
       "495  0.451613                0.322830    0.315789                   0.0   \n",
       "496  0.451613                0.322830    0.315789                   0.0   \n",
       "497  0.322581                0.322830    0.315789                   0.0   \n",
       "498  0.225806                0.322830    0.315789                   0.0   \n",
       "499  0.419355                0.322830    0.315789                   0.0   \n",
       "\n",
       "     Education   Son  Social drinker  Social smoker  Pet    Weight    Height  \\\n",
       "0          0.0  0.50             1.0            0.0  0.2  0.653846  0.272727   \n",
       "1          0.0  0.25             1.0            0.0  0.0  0.807692  0.454545   \n",
       "2          0.0  0.00             1.0            0.0  0.0  0.634615  0.212121   \n",
       "3          0.0  0.50             1.0            1.0  0.0  0.230769  0.151515   \n",
       "4          0.0  0.50             1.0            0.0  0.2  0.653846  0.272727   \n",
       "..         ...   ...             ...            ...  ...       ...       ...   \n",
       "495        0.0  0.00             1.0            0.0  0.0  0.211538  0.212121   \n",
       "496        0.0  0.00             1.0            0.0  0.0  0.211538  0.212121   \n",
       "497        0.0  0.00             0.0            0.0  0.0  0.519231  0.272727   \n",
       "498        0.0  0.50             1.0            0.0  0.0  0.750000  1.000000   \n",
       "499        0.0  0.25             1.0            0.0  0.2  0.326923  0.242424   \n",
       "\n",
       "     Body mass index  \n",
       "0           0.578947  \n",
       "1           0.631579  \n",
       "2           0.631579  \n",
       "3           0.263158  \n",
       "4           0.578947  \n",
       "..               ...  \n",
       "495         0.210526  \n",
       "496         0.210526  \n",
       "497         0.473684  \n",
       "498         0.315789  \n",
       "499         0.315789  \n",
       "\n",
       "[500 rows x 19 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def normalize_dataset():\n",
    "    global AbsentsX,X_testas\n",
    "    x  = AbsentsX.values \n",
    "    x2 = X_test.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    scaler    = min_max_scaler.fit(x)\n",
    "    x_scaled  = scaler.transform(x)\n",
    "    x2_scaled = scaler.transform(x2)\n",
    "    df  = pd.DataFrame(x_scaled)\n",
    "    df2 = pd.DataFrame(x2_scaled)\n",
    "\n",
    "    i = 0\n",
    "    for x in AbsentsX:\n",
    "        AbsentsX[x] = df[i]\n",
    "        X_test [x] = df2[i]\n",
    "        i+=1\n",
    "\n",
    "\n",
    "        \n",
    "def standardize_dataset():\n",
    "    global AbsentsX,X_test\n",
    "    x  =  AbsentsX.values\n",
    "    x2 = X_test.values\n",
    "    standart_scaler = preprocessing.StandardScaler()\n",
    "    scaler = standart_scaler.fit(x)\n",
    "    x_scaled  = scaler.transform(x)\n",
    "    x2_scaled = scaler.transform(x2) \n",
    "    df  = pd.DataFrame(x_scaled)\n",
    "    df2 = pd.DataFrame(x2_scaled)\n",
    "\n",
    "    i = 0\n",
    "    for x in AbsentsX:\n",
    "        AbsentsX[x] = df[i]\n",
    "        X_test[x]  = df2[i]\n",
    "        i+=1\n",
    "        \n",
    "def binarize_dataset():\n",
    "    global AbsentsX,X_test\n",
    "    x  =  AbsentsX.values\n",
    "    x2 = X_test.values\n",
    "    Binarizer = preprocessing.Binarizer()\n",
    "    binarizer = Binarizer.fit(x)\n",
    "    x_scaled  = binarizer.transform(x)\n",
    "    x2_scaled = binarizer.transform(x2) \n",
    "    df  = pd.DataFrame(x_scaled)\n",
    "    df2 = pd.DataFrame(x2_scaled)\n",
    "\n",
    "    i = 0\n",
    "    for x in AbsentsX:\n",
    "        AbsentsX[x] = df[i]\n",
    "        X_test[x]  = df2[i]\n",
    "        i+=1\n",
    "\n",
    "\n",
    "##binarize_dataset()\n",
    "normalize_dataset()\n",
    "##standardize_dataset()\n",
    "AbsentsX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396296</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.339296</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.339296</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.377540</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.418519</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.377540</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.377540</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reason for absence  Month of absence  Day of the week   Seasons  \\\n",
       "0              0.821429          0.727273             1.00  0.000000   \n",
       "1              0.821429          0.727273             1.00  0.000000   \n",
       "2              0.821429          0.727273             0.00  0.000000   \n",
       "3              0.821429          0.727273             0.50  0.000000   \n",
       "4              0.821429          0.727273             0.00  0.000000   \n",
       "..                  ...               ...              ...       ...   \n",
       "235            0.500000          0.545455             0.25  0.000000   \n",
       "236            0.392857          0.545455             0.25  0.000000   \n",
       "237            0.000000         -0.090909             0.25  0.000000   \n",
       "238            0.000000         -0.090909             0.50  0.333333   \n",
       "239            0.000000         -0.090909             1.00  0.666667   \n",
       "\n",
       "     Transportation expense  Distance from Residence to Work  Service time  \\\n",
       "0                  0.225926                         0.446809      0.230769   \n",
       "1                  0.481481                         0.425532      0.423077   \n",
       "2                  0.225926                         0.978723      0.576923   \n",
       "3                  0.396296                         0.446809      0.230769   \n",
       "4                  0.225926                         0.446809      0.230769   \n",
       "..                      ...                              ...           ...   \n",
       "235                0.633333                         0.659574      0.384615   \n",
       "236                0.433333                         0.127660      0.423077   \n",
       "237                0.000000                         0.191489      0.384615   \n",
       "238                0.418519                         0.638298      0.423077   \n",
       "239                0.225926                         0.851064      0.423077   \n",
       "\n",
       "          Age  Work load Average/day   Hit target  Disciplinary failure  \\\n",
       "0    0.096774                0.322830    0.315789                   0.0   \n",
       "1    0.645161                0.322830    0.315789                   0.0   \n",
       "2    0.354839                0.322830    0.315789                   0.0   \n",
       "3    0.032258                0.322830    0.315789                   0.0   \n",
       "4    0.096774                0.322830    0.315789                   0.0   \n",
       "..        ...                     ...         ...                   ...   \n",
       "235  0.193548                0.339296    0.631579                   0.0   \n",
       "236  0.322581                0.339296    0.631579                   0.0   \n",
       "237  0.419355                0.377540    0.736842                   0.0   \n",
       "238  0.387097                0.377540    0.736842                   0.0   \n",
       "239  0.838710                0.377540    0.736842                   0.0   \n",
       "\n",
       "     Education   Son  Social drinker  Social smoker  Pet    Weight    Height  \\\n",
       "0          1.0  0.00             0.0            0.0  0.0  0.000000  0.242424   \n",
       "1          0.0  0.50             0.0            0.0  0.2  0.576923  0.060606   \n",
       "2          0.0  0.00             1.0            0.0  0.0  0.634615  0.212121   \n",
       "3          0.0  0.25             0.0            0.0  0.4  0.250000  0.181818   \n",
       "4          1.0  0.00             0.0            0.0  0.0  0.000000  0.242424   \n",
       "..         ...   ...             ...            ...  ...       ...       ...   \n",
       "235        0.0  0.50             1.0            0.0  0.2  0.653846  0.272727   \n",
       "236        1.0  0.25             0.0            0.0  0.2  0.615385  0.272727   \n",
       "237        0.0  0.25             1.0            0.0  1.6  0.807692  0.212121   \n",
       "238        0.0  0.50             1.0            0.0  0.4  0.846154  0.212121   \n",
       "239        0.0  0.25             0.0            0.0  0.2  0.403846  0.363636   \n",
       "\n",
       "     Body mass index  \n",
       "0           0.000000  \n",
       "1           0.684211  \n",
       "2           0.631579  \n",
       "3           0.263158  \n",
       "4           0.000000  \n",
       "..               ...  \n",
       "235         0.578947  \n",
       "236         0.526316  \n",
       "237         0.789474  \n",
       "238         0.842105  \n",
       "239         0.315789  \n",
       "\n",
       "[240 rows x 19 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reinserir a coluna absent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsentsX.insert(len(AbsentsX.columns),'Absent',AbsentsY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancear o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "def balance_dataset(nr_0,nr_1):\n",
    "    global AbsentsX\n",
    "    abs_shuffled = AbsentsX.sample(frac=1,random_state=4)\n",
    "    A0 = abs_shuffled.loc[abs_shuffled['Absent'] == 1].sample(n=nr_0,random_state=4)\n",
    "    A1 = abs_shuffled.loc[abs_shuffled['Absent'] == 0].sample(n=nr_1,random_state=4)\n",
    "    \n",
    "    balanced_absents = pd.concat([A0,A1])\n",
    "    AbsentsX = balanced_absents.sample(frac=1,random_state=4)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "A0 = len(AbsentsX[AbsentsX['Absent'] == 0])\n",
    "A1 = len(AbsentsX[AbsentsX['Absent'] == 1])\n",
    "\n",
    "nr_elements_dataset = A0\n",
    "\n",
    "if A1 < A0:\n",
    "    nr_elements_dataset = A1\n",
    "\n",
    "print(nr_elements_dataset)\n",
    "##balance_dataset(nr_elements_dataset,nr_elements_dataset)\n",
    "balance_dataset(125,nr_elements_dataset)\n",
    "\n",
    "print(len(AbsentsX))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removemos os outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = AbsentsX.quantile(0.975)\n",
    "q4 = AbsentsX.quantile(0.025)\n",
    "\n",
    "\n",
    "OUTLIER_COLUMNS = ['Reason for absence',\"Age\",\"Transportation expense\",\n",
    "                  \"Service time\",\"Work load Average/day \",\"Hit target\",\n",
    "                  \"Weight\",\"Height\",\"Body mass index\"]\n",
    "\n",
    "def remove_outliers(OUTLIER_COLUMNS):\n",
    "    global AbsentsX\n",
    "    for i in OUTLIER_COLUMNS:\n",
    "        AbsentsX = AbsentsX.drop(AbsentsX[AbsentsX[i] > q1[i]].index)\n",
    "        AbsentsX = AbsentsX.drop(AbsentsX[AbsentsX[i] < q4[i]].index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "remove_outliers(OUTLIER_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Absents[Absents['Absent'] == 1]))\n",
    "print(len(Absents[Absents['Absent'] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection + extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Absent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>465 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reason for absence  Month of absence  Seasons  \\\n",
       "0              0.928571          0.545455      0.0   \n",
       "1              0.000000          0.545455      0.0   \n",
       "2              0.821429          0.545455      0.0   \n",
       "3              0.250000          0.545455      0.0   \n",
       "4              0.821429          0.545455      0.0   \n",
       "..                  ...               ...      ...   \n",
       "495            1.000000          0.727273      0.0   \n",
       "496            1.000000          0.727273      0.0   \n",
       "497            1.000000          0.727273      0.0   \n",
       "498            0.821429          0.727273      0.0   \n",
       "499            1.000000          0.727273      0.0   \n",
       "\n",
       "     Distance from Residence to Work  Service time       Age  \\\n",
       "0                           0.659574      0.384615  0.193548   \n",
       "1                           0.170213      0.576923  0.741935   \n",
       "2                           0.978723      0.576923  0.354839   \n",
       "3                           0.000000      0.423077  0.387097   \n",
       "4                           0.659574      0.384615  0.193548   \n",
       "..                               ...           ...       ...   \n",
       "495                         0.425532      0.500000  0.451613   \n",
       "496                         0.425532      0.500000  0.451613   \n",
       "497                         0.106383      0.269231  0.322581   \n",
       "498                         0.148936      0.423077  0.225806   \n",
       "499                         0.553191      0.346154  0.419355   \n",
       "\n",
       "     Disciplinary failure  Education   Son  Social drinker  Social smoker  \\\n",
       "0                     0.0        0.0  0.50             1.0            0.0   \n",
       "1                     1.0        0.0  0.25             1.0            0.0   \n",
       "2                     0.0        0.0  0.00             1.0            0.0   \n",
       "3                     0.0        0.0  0.50             1.0            1.0   \n",
       "4                     0.0        0.0  0.50             1.0            0.0   \n",
       "..                    ...        ...   ...             ...            ...   \n",
       "495                   0.0        0.0  0.00             1.0            0.0   \n",
       "496                   0.0        0.0  0.00             1.0            0.0   \n",
       "497                   0.0        0.0  0.00             0.0            0.0   \n",
       "498                   0.0        0.0  0.50             1.0            0.0   \n",
       "499                   0.0        0.0  0.25             1.0            0.0   \n",
       "\n",
       "     Pet    Weight    Height  Body mass index  Absent  \n",
       "0    0.2  0.653846  0.272727         0.578947       1  \n",
       "1    0.0  0.807692  0.454545         0.631579       0  \n",
       "2    0.0  0.634615  0.212121         0.631579       1  \n",
       "3    0.0  0.230769  0.151515         0.263158       1  \n",
       "4    0.2  0.653846  0.272727         0.578947       1  \n",
       "..   ...       ...       ...              ...     ...  \n",
       "495  0.0  0.211538  0.212121         0.210526       0  \n",
       "496  0.0  0.211538  0.212121         0.210526       0  \n",
       "497  0.0  0.519231  0.272727         0.473684       1  \n",
       "498  0.0  0.750000  1.000000         0.315789       1  \n",
       "499  0.2  0.326923  0.242424         0.315789       1  \n",
       "\n",
       "[465 rows x 16 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "AbsentsY = AbsentsX['Absent']\n",
    "AbsentsX = AbsentsX.drop(columns=\"Absent\")\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "Columns = [x for x in AbsentsX]\n",
    "\n",
    "def feature_selectionKBest(nr_features):\n",
    "    \n",
    "    global AbsentsX,AbsentsY,X_test\n",
    "    feature_selector = SelectKBest(chi2,k=nr_features).fit(AbsentsX,AbsentsY)\n",
    "    \n",
    "    \n",
    "    keep_feature = feature_selector.get_support()\n",
    "    \n",
    "    droping_columns = [Columns[x] for x in range(len(keep_feature))\n",
    "                          if keep_feature[x] == 0]\n",
    "    \n",
    "    AbsentsX = AbsentsX.drop(columns=droping_columns)\n",
    "    X_test  = X_test.drop(columns=droping_columns)\n",
    "    \n",
    "    \n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "def feature_selectionRFE(nr_features):\n",
    "    \n",
    "    global AbsentsX,AbsentsY,X_test\n",
    "    estimator = SVR(kernel=\"linear\")\n",
    "    selector = RFE(estimator, nr_features, step=1)\n",
    "    selector = selector.fit(AbsentsX,AbsentsY)\n",
    "        \n",
    "    keep_feature = selector.get_support()\n",
    "    \n",
    "    droping_columns = [Columns[x] for x in range(len(keep_feature))\n",
    "                          if keep_feature[x] == 0]\n",
    "    \n",
    "    AbsentsX = AbsentsX.drop(columns=droping_columns)\n",
    "    X_test  = X_test.drop(columns=droping_columns)\n",
    "    \n",
    "\n",
    "\n",
    "def featureExtraction(correlation_coefficient):\n",
    "    global AbsentsX,AbsentsY,X_test,Columns\n",
    "    correlation = AbsentsX.corr()\n",
    "    \n",
    "    new_columns = list()\n",
    "    \n",
    "    \n",
    "    while(len(Columns) > 0):\n",
    "        copy_columns = list(Columns)\n",
    "        new_column = list()\n",
    "        column = Columns[0]\n",
    "        Columns.remove(column)\n",
    "        new_column.append(column)\n",
    "        for i in copy_columns:\n",
    "            if(i != column):\n",
    "                if AbsentsX[column].corr(AbsentsX[i]) > correlation_coefficient:\n",
    "                    new_column.append(i)\n",
    "                    Columns.remove(i)\n",
    "        new_columns.append(new_column)\n",
    "              \n",
    "    \n",
    "    for x in new_columns:\n",
    "        averages = list()\n",
    "        for index,row in AbsentsX.iterrows():\n",
    "                average = 0;\n",
    "                for i in x:\n",
    "                    average += row[i]\n",
    "                average = average/len(x)\n",
    "                averages.append(average)\n",
    "                            \n",
    "        AbsentsX = AbsentsX.drop(columns = x)\n",
    "        AbsentsX.insert(len(AbsentsX.columns),\" + \".join(x),averages)    \n",
    "    \n",
    "                \n",
    "    \n",
    "    for x in new_columns:\n",
    "        averages = list()\n",
    "        for index,row in X_test.iterrows():\n",
    "                average = 0;\n",
    "                for i in x:\n",
    "                    average += row[i]\n",
    "                average = average/len(x)\n",
    "                averages.append(average)\n",
    "                            \n",
    "        X_test = X_test.drop(columns = x)\n",
    "        X_test.insert(len(X_test.columns),\" + \".join(x),averages)    \n",
    "\n",
    "        \n",
    "##feature_selectionKBest(8)\n",
    "\n",
    "feature_selectionRFE(15)\n",
    "\n",
    "##featureExtraction(0.5)\n",
    "\n",
    "sns.heatmap(AbsentsX.corr())      \n",
    "AbsentsX.insert(len(AbsentsX.columns),\"Absent\",AbsentsY)\n",
    "AbsentsX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.194471</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.194471</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason for absence  Month of absence  Day of the week  Seasons  \\\n",
       "0            0.928571          0.545455             0.25      0.0   \n",
       "1            0.000000          0.545455             0.25      0.0   \n",
       "\n",
       "   Transportation expense  Distance from Residence to Work  Service time  \\\n",
       "0                0.633333                         0.659574      0.384615   \n",
       "1                0.000000                         0.170213      0.576923   \n",
       "\n",
       "        Age  Work load Average/day   Hit target  \n",
       "0  0.193548                0.194471    0.842105  \n",
       "1  0.741935                0.194471    0.842105  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AbsentsX[AbsentsX.columns[:10]].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight + Body mass index</th>\n",
       "      <th>Height</th>\n",
       "      <th>Absent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.616397</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719636</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education   Son  Social drinker  Social smoker  Pet  \\\n",
       "0        0.0  0.50             1.0            0.0  0.2   \n",
       "1        0.0  0.25             1.0            0.0  0.0   \n",
       "\n",
       "   Weight + Body mass index    Height  Absent  \n",
       "0                  0.616397  0.272727       1  \n",
       "1                  0.719636  0.454545       0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AbsentsX[AbsentsX.columns[10:]].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc  = list()\n",
    "pr  = list()\n",
    "rfc = list()\n",
    "pac = list()\n",
    "nc  = list()\n",
    "rnc = list()\n",
    "etc = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "\\hline\n",
      "ru0 & 77.92\\\\\n",
      "\\hline\n",
      "ru1 & 80.83\\\\\n",
      "\\hline\n",
      "ru2 & 79.17\\\\\n",
      "\\hline\n",
      "ru3 & 80.42\\\\\n",
      "\\hline\n",
      "ru4 & 61.25\\\\\n",
      "\\hline\n",
      "ru5 & 40.83\\\\\n",
      "\\hline\n",
      "ru6 & 80.83\\\\\n",
      "\\hline\n",
      "ru7 & 80.83\\\\\n",
      "\\hline\n",
      "ru8 & 80.83\\\\\n"
     ]
    }
   ],
   "source": [
    "def get_latex_list(l):\n",
    "    for i in range(len(l)):\n",
    "        print(\"\\hline\\n\" + \"ru\" + str(i) + \" & \" + str(round(l[i]*100,2)) + \"\\\\\\\\\" )\n",
    "        \n",
    "print(len(etc))        \n",
    "get_latex_list(etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8166666666666667, 0.8166666666666667, 0.8166666666666667, 0.8166666666666667, 0.8166666666666667]\n",
      "[0.8166666666666667, 0.7625, 0.7791666666666667, 0.8041666666666667, 0.24583333333333332]\n",
      "[0.7833333333333333, 0.775, 0.5291666666666667, 0.8041666666666667, 0.575]\n",
      "[0.8166666666666667, 0.21666666666666667, 0.7041666666666667, 0.8041666666666667, 0.20416666666666666]\n",
      "[0.6875, 0.6125, 0.6583333333333333, 0.8041666666666667, 0.7041666666666667]\n",
      "[-1, -1, 0.8166666666666667, -1]\n",
      "[0.7791666666666667, 0.8083333333333333, 0.7916666666666666, 0.8041666666666667, 0.6125]\n"
     ]
    }
   ],
   "source": [
    "print(dc)\n",
    "print(pr)\n",
    "print(rfc)\n",
    "print(pac)\n",
    "print(nc)\n",
    "print(rnc)\n",
    "print(etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = AbsentsX.drop(columns= 'Absent')\n",
    "Y = AbsentsX['Absent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression\n",
    "### Area under the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7916666666666666"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##X_test = X_new.transform(X_test)\n",
    "\n",
    "##X = Absents.drop('Absent',axis = 1)\n",
    "##Y = Absents['Absent']\n",
    "\n",
    "lm = LinearRegression(fit_intercept=False,normalize=True,copy_X= False)\n",
    "lm.fit(X,Y)\n",
    "predictions = lm.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "predictions = [int( x  > 0.5) for x in predictions]\n",
    "print(predictions)\n",
    "accuracy_score(Y_test['Absent'],predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'copy_X': False, 'fit_intercept': True, 'n_jobs': None, 'normalize': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20416666666666666"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'fit_intercept': [True,False], 'normalize': [True,False], 'copy_X': [False,True],'n_jobs': [None,1,2,4,8,16,32]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(LinearRegression(),param_grid,refit=True,verbose=0,cv=5)\n",
    "grid.fit(X,Y)\n",
    "print(grid.best_params_)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "grid_predictions = [int( x  > 0.5) for x in grid_predictions]\n",
    "accuracy_score(Y_test['Absent'],grid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier(strategy= 'most_frequent')\n",
    "clf.fit(X,Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'strategy': 'most_frequent'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugoa\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'strategy': ['stratified','most_frequent',\n",
    "                          'prior','uniform']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(DummyClassifier(),param_grid,refit=True,verbose=0)\n",
    "grid.fit(X,Y)\n",
    "print(grid.best_params_)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],grid_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7625"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(solver = 'saga')\n",
    "LR.fit(X,Y)\n",
    "predictions = LR.predict(X_test)\n",
    "print(predictions)\n",
    "accuracy_score(Y_test['Absent'],predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1\n",
      " 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7416666666666667"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "predictions = kmeans.predict(X_test)\n",
    "print(predictions)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1\n",
      " 1 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1\n",
      " 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1\n",
      " 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42083333333333334"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X,Y)\n",
    "predictions = knn.predict(X_test)\n",
    "print(predictions)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(gamma = 'auto')\n",
    "model.fit(X,Y)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugoa\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.832, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.819, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.865, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.858, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "grid.fit(X,Y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],grid_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-895160768884>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    611\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[0;32m    612\u001b[0m                                        dtype=np.float64)\n\u001b[1;32m--> 613\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    718\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X,Y)\n",
    "predictions = classifier.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-d7ea4f66cc9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pr' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X, Y)\n",
    "predictions = clf.predict(X_test)\n",
    "pr.append(accuracy_score(Y_test['Absent'],predictions))\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer percetron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20416666666666666"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X,Y)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.325"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X,Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 200)\n",
    "\n",
    "##params_rf = {'n_estimators': [50, 100, 200,400]}\n",
    "\n",
    "##rf_gs = GridSearchCV(rf, params_rf, cv=5)\n",
    "\n",
    "##rf_gs.fit(X, Y)\n",
    "\n",
    "rf.fit(X,Y)\n",
    "\n",
    "##print(rf_gs.best_params_)\n",
    "predictions = rf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PassiveAgressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pac' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-9834d1583783>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pac' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=0,\n",
    "tol=1e-3)\n",
    "clf.fit(X, Y)\n",
    "predictions = clf.predict(X_test)\n",
    "pac.append(accuracy_score(Y_test['Absent'],predictions))\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35833333333333334"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "clf = NearestCentroid()\n",
    "clf.fit(X, Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RadiusNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No neighbors found for test samples [2, 5, 6, 7, 9, 10, 11, 13, 14, 16, 17, 19, 20, 22, 32, 35, 37, 40, 41, 44, 48, 49, 51, 53, 54, 55, 56, 61, 62, 63, 64, 69, 76, 81, 83, 84, 88, 90, 92, 93, 94, 95, 97, 98, 102, 103, 105, 107, 110, 112, 115, 116, 118, 123, 125, 131, 132, 136, 138, 141, 143, 145, 146, 147, 149, 150, 162, 163, 170, 175, 178, 181, 182, 183, 185, 188, 190, 202, 206, 210, 211, 212, 214, 216, 221, 224, 225, 226, 237], you can try using larger radius, give a label for outliers, or consider removing them from your dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-51bc348b5d0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRadiusNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m                              \u001b[1;34m'give a label for outliers, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m                              \u001b[1;34m'or consider removing them from your dataset.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m                              % outliers)\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No neighbors found for test samples [2, 5, 6, 7, 9, 10, 11, 13, 14, 16, 17, 19, 20, 22, 32, 35, 37, 40, 41, 44, 48, 49, 51, 53, 54, 55, 56, 61, 62, 63, 64, 69, 76, 81, 83, 84, 88, 90, 92, 93, 94, 95, 97, 98, 102, 103, 105, 107, 110, 112, 115, 116, 118, 123, 125, 131, 132, 136, 138, 141, 143, 145, 146, 147, 149, 150, 162, 163, 170, 175, 178, 181, 182, 183, 185, 188, 190, 202, 206, 210, 211, 212, 214, 216, 221, 224, 225, 226, 237], you can try using larger radius, give a label for outliers, or consider removing them from your dataset."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "clf = RadiusNeighborsClassifier(radius=1.9)\n",
    "clf.fit(X,Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "                            \n",
    "clf = BaggingClassifier(base_estimator=SVC(gamma='auto'),\n",
    "                       n_estimators=10, random_state=0)\n",
    "clf.fit(X, Y)\n",
    "predictions = clf.predict(X_test)\n",
    "print(predictions)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "### needs sklearn version 0.23 or  above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StackingClassifier' from 'sklearn.ensemble' (C:\\Users\\hugoa\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-85306df21c21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'StackingClassifier' from 'sklearn.ensemble' (C:\\Users\\hugoa\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42 0.27 0.02 0.07 0.05 0.05 0.   0.01 0.01 0.   0.01 0.   0.05 0.02\n",
      " 0.02]\n",
      "1 : predicted1 actual 0\n",
      "17 : predicted1 actual 0\n",
      "27 : predicted1 actual 0\n",
      "28 : predicted1 actual 0\n",
      "29 : predicted1 actual 0\n",
      "30 : predicted1 actual 0\n",
      "31 : predicted1 actual 0\n",
      "38 : predicted1 actual 0\n",
      "54 : predicted1 actual 0\n",
      "64 : predicted1 actual 0\n",
      "65 : predicted1 actual 0\n",
      "66 : predicted1 actual 0\n",
      "67 : predicted1 actual 0\n",
      "68 : predicted1 actual 0\n",
      "75 : predicted1 actual 0\n",
      "91 : predicted1 actual 0\n",
      "101 : predicted1 actual 0\n",
      "102 : predicted1 actual 0\n",
      "103 : predicted1 actual 0\n",
      "104 : predicted1 actual 0\n",
      "105 : predicted1 actual 0\n",
      "112 : predicted1 actual 0\n",
      "128 : predicted1 actual 0\n",
      "138 : predicted1 actual 0\n",
      "139 : predicted1 actual 0\n",
      "140 : predicted1 actual 0\n",
      "141 : predicted1 actual 0\n",
      "142 : predicted1 actual 0\n",
      "149 : predicted1 actual 0\n",
      "165 : predicted1 actual 0\n",
      "175 : predicted1 actual 0\n",
      "176 : predicted1 actual 0\n",
      "177 : predicted1 actual 0\n",
      "178 : predicted1 actual 0\n",
      "179 : predicted1 actual 0\n",
      "186 : predicted1 actual 0\n",
      "202 : predicted1 actual 0\n",
      "212 : predicted1 actual 0\n",
      "213 : predicted1 actual 0\n",
      "214 : predicted1 actual 0\n",
      "215 : predicted1 actual 0\n",
      "216 : predicted1 actual 0\n",
      "223 : predicted1 actual 0\n",
      "239 : predicted1 actual 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators = 100, random_state=0)\n",
    "clf.fit(X, Y)\n",
    "print(clf.feature_importances_)\n",
    "preditions = clf.predict(X_test)\n",
    "for x in range(len(predictions)):\n",
    "    if(predictions[x] != Y_test['Absent'][x]):\n",
    "        print(str(x) + \" : predicted\" + str(predictions[x]) + \" actual \" + str(Y_test['Absent'][x]) ) \n",
    "        \n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(multi_class='multinomial',solver = 'saga', random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf1 = VotingClassifier(estimators=[\n",
    "         ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "eclf1 = eclf1.fit(X.values, Y.values)\n",
    "preditions = eclf1.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf2 = VotingClassifier(estimators=[\n",
    "   ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "  voting='soft')\n",
    "eclf2 = eclf2.fit(X, Y)\n",
    "\n",
    "preditions = eclf2.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2791666666666667"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf3 = VotingClassifier(estimators=[\n",
    " ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    " voting='soft', weights=[2,1,1],\n",
    " flatten_transform=True)\n",
    "eclf3 = eclf3.fit(X, Y)\n",
    "predictions = eclf3.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'etc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-5c34bf85dc86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0metc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'etc' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X,Y)\n",
    "predictions = clf.predict(X_test)\n",
    "etc.append(accuracy_score(Y_test['Absent'],predictions))\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parametrization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(gamma = 'auto')\n",
    "model.fit(X,Y)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugoa\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.832, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.819, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.865, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.858, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.839, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.794, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "grid.fit(X,Y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15454fefa48>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "print(accuracy_score(Y_test['Absent'],grid_predictions))\n",
    "plt.scatter(Y_test['Absent'],grid_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Radius Neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No neighbors found for test samples [2, 5, 6, 7, 9, 10, 11, 13, 14, 16, 17, 19, 20, 22, 32, 35, 37, 40, 41, 44, 48, 49, 51, 53, 54, 55, 56, 61, 62, 63, 64, 69, 76, 81, 83, 84, 88, 90, 92, 93, 94, 95, 97, 98, 102, 103, 105, 107, 110, 112, 115, 116, 118, 123, 125, 131, 132, 136, 138, 141, 143, 145, 146, 147, 149, 150, 162, 163, 170, 175, 178, 181, 182, 183, 185, 188, 190, 202, 206, 210, 211, 212, 214, 216, 221, 224, 225, 226, 237], you can try using larger radius, give a label for outliers, or consider removing them from your dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-7871609e1897>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRadiusNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m                              \u001b[1;34m'give a label for outliers, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m                              \u001b[1;34m'or consider removing them from your dataset.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m                              % outliers)\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No neighbors found for test samples [2, 5, 6, 7, 9, 10, 11, 13, 14, 16, 17, 19, 20, 22, 32, 35, 37, 40, 41, 44, 48, 49, 51, 53, 54, 55, 56, 61, 62, 63, 64, 69, 76, 81, 83, 84, 88, 90, 92, 93, 94, 95, 97, 98, 102, 103, 105, 107, 110, 112, 115, 116, 118, 123, 125, 131, 132, 136, 138, 141, 143, 145, 146, 147, 149, 150, 162, 163, 170, 175, 178, 181, 182, 183, 185, 188, 190, 202, 206, 210, 211, 212, 214, 216, 221, 224, 225, 226, 237], you can try using larger radius, give a label for outliers, or consider removing them from your dataset."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "\n",
    "clf = RadiusNeighborsClassifier(radius=1.9)\n",
    "clf.fit(X,Y)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'leaf_size': 15, 'radius': 1.9}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No neighbors found for test samples [2, 5, 6, 7, 9, 10, 11, 13, 14, 16, 17, 19, 20, 22, 32, 35, 37, 40, 41, 44, 48, 49, 51, 53, 54, 55, 56, 61, 62, 63, 64, 69, 76, 81, 83, 84, 88, 90, 92, 93, 94, 95, 97, 98, 102, 103, 105, 107, 110, 112, 115, 116, 118, 123, 125, 131, 132, 136, 138, 141, 143, 145, 146, 147, 149, 150, 162, 163, 170, 175, 178, 181, 182, 183, 185, 188, 190, 202, 206, 210, 211, 212, 214, 216, 221, 224, 225, 226, 237], you can try using larger radius, give a label for outliers, or consider removing them from your dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-85cc95fe3969>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgrid_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \"\"\"\n\u001b[0;32m    456\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m                              \u001b[1;34m'give a label for outliers, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m                              \u001b[1;34m'or consider removing them from your dataset.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m                              % outliers)\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No neighbors found for test samples [2, 5, 6, 7, 9, 10, 11, 13, 14, 16, 17, 19, 20, 22, 32, 35, 37, 40, 41, 44, 48, 49, 51, 53, 54, 55, 56, 61, 62, 63, 64, 69, 76, 81, 83, 84, 88, 90, 92, 93, 94, 95, 97, 98, 102, 103, 105, 107, 110, 112, 115, 116, 118, 123, 125, 131, 132, 136, 138, 141, 143, 145, 146, 147, 149, 150, 162, 163, 170, 175, 178, 181, 182, 183, 185, 188, 190, 202, 206, 210, 211, 212, 214, 216, 221, 224, 225, 226, 237], you can try using larger radius, give a label for outliers, or consider removing them from your dataset."
     ]
    }
   ],
   "source": [
    "param_grid = {'algorithm':['auto','ball_tree', 'kd_tree', 'brute'],'radius':[1.9,2.5,3,4,5,10],\n",
    "             'leaf_size':[15,30,45,50]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(RadiusNeighborsClassifier(),param_grid,cv=3,refit=True,verbose=0)\n",
    "grid.fit(X,Y)\n",
    "print(grid.best_params_)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "accuracy_score(Y_test['Absent'],grid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8208333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15453238b88>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(accuracy_score(Y_test['Absent'],grid_predictions))\n",
    "plt.scatter(Y_test['Absent'],grid_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators = 100, random_state=0)\n",
    "clf.fit(X, Y)\n",
    "print(clf.feature_importances_)\n",
    "preditions = clf.predict(X_test) \n",
    "        \n",
    "accuracy_score(Y_test['Absent'],predictions)\n",
    "plt.scatter(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=1 ................\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=1, score=0.860, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=1 ................\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=1, score=0.810, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=1 ................\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=1, score=0.890, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=1 ................\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=1, score=0.870, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=1 ................\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=1, score=0.840, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=10 ...............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=10, score=0.860, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=10 ...............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=10, score=0.810, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=10 ...............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=10, score=0.890, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=10 ...............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=10, score=0.870, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=10 ...............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=10, score=0.840, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=100 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=100, score=0.860, total=   0.2s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=100 ..............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=100, score=0.790, total=   0.1s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=100 ..............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=100, score=0.780, total=   0.1s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=100 ..............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=100, score=0.860, total=   0.2s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=100 ..............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=100, score=0.840, total=   0.1s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=1000 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=1000, score=0.810, total=   1.6s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=1000 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=1000, score=0.750, total=   1.5s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=1000 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=1000, score=0.690, total=   1.5s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=1000 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=1000, score=0.840, total=   1.4s\n",
      "[CV] algorithm=SAMME, learning_rate=1, n_estimators=1000 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=1, n_estimators=1000, score=0.850, total=   1.3s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=1 ..............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=1, score=0.860, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=1 ..............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=1, score=0.810, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=1 ..............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=1, score=0.890, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=1 ..............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=1, score=0.870, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=1 ..............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=1, score=0.840, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=10 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=10, score=0.860, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=10 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=10, score=0.810, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=10 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=10, score=0.890, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=10 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=10, score=0.870, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=10 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=10, score=0.840, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=100 ............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=100, score=0.860, total=   0.1s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=100 ............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=100, score=0.810, total=   0.1s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=100 ............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=100, score=0.890, total=   0.1s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=100 ............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=100, score=0.870, total=   0.2s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=100 ............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=100, score=0.840, total=   0.1s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=1000 ...........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=1000, score=0.860, total=   1.3s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=1000 ...........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=1000, score=0.810, total=   1.4s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=1000 ...........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=1000, score=0.900, total=   1.4s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=1000 ...........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=1000, score=0.870, total=   1.6s\n",
      "[CV] algorithm=SAMME, learning_rate=0.1, n_estimators=1000 ...........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.1, n_estimators=1000, score=0.840, total=   1.6s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=1 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=1, score=0.860, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=1 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=1, score=0.810, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=1 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=1, score=0.890, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=1 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=1, score=0.870, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=1 .............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=1, score=0.840, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=10 ............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=10, score=0.860, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=10 ............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=10, score=0.810, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=10 ............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=10, score=0.890, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=10 ............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=10, score=0.870, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=10 ............\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=10, score=0.840, total=   0.0s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=100 ...........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=100, score=0.860, total=   0.1s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=100 ...........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=100, score=0.810, total=   0.2s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=100 ...........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=100, score=0.890, total=   0.2s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=100 ...........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=100, score=0.870, total=   0.4s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=100 ...........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=100, score=0.840, total=   0.4s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=1000 ..........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=1000, score=0.860, total=   2.2s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=1000 ..........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=1000, score=0.810, total=   1.5s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=1000 ..........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=1000, score=0.890, total=   1.7s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=1000 ..........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=1000, score=0.870, total=   1.6s\n",
      "[CV] algorithm=SAMME, learning_rate=0.01, n_estimators=1000 ..........\n",
      "[CV]  algorithm=SAMME, learning_rate=0.01, n_estimators=1000, score=0.840, total=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   26.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 1000}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8208333333333333"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [1, 10, 100, 1000], 'learning_rate': [1,0.1,0.01], 'algorithm': ['SAMME']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(AdaBoostClassifier(),param_grid,refit=True,verbose=3,cv=5)\n",
    "grid.fit(X,Y)\n",
    "print(grid.best_params_)\n",
    "accuracy_score(Y_test['Absent'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsentsY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
